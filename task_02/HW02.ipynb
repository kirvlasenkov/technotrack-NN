{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №2 - обучение модели трехслойного перцептрона методом градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "В качестве теоретического задания в этом ДЗ предлагается провести вывод функции ошибки для задачи регрессии в предположении, что целевая переменная подчиняется распределению Лапласа. Также предлагается воспользоваться байесовским выводом и в том же предположении относительно распределения целевой переменной вывести форму функции потерь с условием лапласовского априорного распределения параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Решение задачи 1</h1></center>\n",
    "\n",
    "Пусть целевая переменная имеет <a href=https://en.wikipedia.org/wiki/Laplace_distribution>распределение Лапласа</a>, то есть ее функция плотности задается, как $\\rho(x|\\mu, \\sigma) = \t{\\displaystyle {\\frac {1}{2\\sigma}}\\exp \\left(-{\\frac {|x-\\mu |}{\\sigma}}\\right)}$, где $\\mu \\in R_{+}$  и $\\sigma \\in R$ -  некоторые параметры. Также имеет место быть постановка предположения, что $y_{true} = y_{pred}(x, w) + \\epsilon$, где $\\epsilon$ - ошибка, имеющая распределение $Laplace(\\mu_{\\epsilon}, \\sigma_{\\epsilon})$, то тогда y_{true} также случайная величина, но имеющая распределение с параметрами $\\mu = \\mu_{\\epsilon} + y_{pred}$ и $\\sigma = \\sigma_{\\epsilon}$.\n",
    "\n",
    "Пусть формально у нас есть какая-то выборка данных $Y$, которая состоит из некоторого набора элементов $\\{y_i\\}_{i=1}^n$, и, предполагая, что данные у нас независимо и одинаково распределенные с распределением Лапласа, зависящие от некоторого, возможно многомерного, параметра $\\theta$, можно вывести оптимальную оценку этого параметра. Ниже будет представлен вывод оценки через **оценку максимального правдоподобия** и **максимизацию апостериорного распределения**.\n",
    "\n",
    "## Оценка максимального правдоподобия\n",
    "Данный подход оценивает параметр $\\theta$ через следующую цепочку рассуждений:\n",
    "$$\n",
    "\\theta_{MLE} =\n",
    "argmax(\\rho(Y|\\theta)) =\n",
    "argmax(\\rho(y_1, y_2...y_n|\\theta)) =\n",
    "argmax(\\prod\\limits_{i=1}^n\\rho(y_i|\\theta)) =\n",
    "argmax(\\sum\\limits_{i=1}^n\\log(\\rho(y_i|\\theta))),\n",
    "$$\n",
    "Соответственно, если $Y$ порождены распределением Лапласа, то при подстановке соответствующей функции плотности получим:\n",
    "\n",
    "$$\\theta_{MLE}= argmax(-n\\log (2\\sigma)-\\frac{1}{\\sigma}\\sum_{t=1}^N |x_t-\\mu - y^i_{pred}(\\theta)|),$$ а так как экстремум ищется по $\\theta$, то данная задача эквивалентна следующей (при условии также, что $\\mu = 0$, а $\\sigma = 1$:\n",
    "$$\\theta_{MLE} = argmin(\\sum\\limits_{i=1}^n|y_i - y^i_{pred}|),$$\n",
    "что и является в чистом виде $MAE$.\n",
    "\n",
    "## Оценка апостериорного максимума \n",
    "Теперь помимо выше сделанных предположений о $Y$, также предположим, что $\\theta \\sim Laplace(\\mu_{\\theta}, \\sigma_{\\theta})$ (что есть априорным распределением).\n",
    "Тогда, опираясь на метод максимизации апостериорного распределения будем искать $\\theta_{MAP}$, как решение задачи:\n",
    "$$\\theta_{MAP} = argmax(\\rho(\\theta | Y)),$$\n",
    "что в силу формулы Байеса  принимает вид:\n",
    "$$\\theta_{MAP} = \n",
    "argmax(\\rho(\\theta | Y)) = \n",
    "argmax(\\frac{\\rho(Y | \\theta) \\rho(\\theta)}{  \\rho(Y) }) = \n",
    "argmax(\\rho(Y | \\theta) \\rho(\\theta)) = \n",
    "argmax(log(\\rho(Y | \\theta)) + log(\\rho(\\theta))) = \n",
    "argmax(\\sum\\limits_{i=1}^n log(\\rho(y_i | \\theta) + log(\\rho(\\theta)))\n",
    "$$\n",
    "Если брать во внимание сделанные предположения о $\\theta$ и $Y$:\n",
    "$$\\theta_{MAP} = \n",
    "argmax( -n\\log (2\\sigma)-\\frac{1}{\\sigma}\\sum_{t=1}^N |x_t-\\mu - y^i_{pred}(\\theta)| -n\\log (2\\sigma_{\\theta}) - \\sum\\limits_{i=1}^n |\\theta_{i}|)\n",
    "$$\n",
    "что и при соответствующих парематрах модели (среднего и дисперсии), дает следующую задачу:\n",
    "$$\\theta_{MLE} = argmin(\\sum\\limits_{i=1}^n|y_i - y^i_{pred}| + \\sum\\limits_{i=1}^n |\\theta_{i}|),$$\n",
    "а это ничто иное как $MAE$ с $L^1$ - регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2\n",
    "В этом ДЗ предлагается реализовать модель трехслойного перцептрона и обучение этой модели методом градиентного спуска.\n",
    "\n",
    "На этот раз предлагается работать с реальными данными. Данные представляют из себя набор рукописных цифр. Это изображения размером 28х28. Каждому изображению поставлен в соответствие класс - арабская цифра. Задача модели - определить цифру, соответствующую произвольному изображению из тестового набора данных.\n",
    "\n",
    "Так же, как и в ДЗ №1, предлагается реализовать функцию потерь и саму модель перцептрона в манере, схожей с построением модулей фреймворка pytorch.\n",
    "\n",
    "В решении ожидается наличие следующих ключевых составляющих:<br />\n",
    "\n",
    "- (текст) формулировка задачи +\n",
    "- (текст) формулировка признакового описания объектов +\n",
    "- (текст, формулы) формулировка модели многослойного перцептрона +\n",
    "- (текст, формулы) формулировка функции ошибки +\n",
    "- (текст, формулы) формулировка меры качества модели +\n",
    "- (текст, код и диаграммы) исследование исходных данных: распределение признаков и другие действия, дающие понимание о характере исходных  данных +\n",
    "- (текст, код, диаграммы) фильтрация признаков (при необходимости), порождение признаков (при необходимости) +\n",
    "- (формулы, код, результаты, коммментарии) обучение модели методом градиентного спуска +\n",
    "- (код, результаты, комментарии) оценка качества модели на валидационной выборке +\n",
    "\n",
    "#### Код решения:\n",
    "(можно использовать предлагаемые шаблоны)\n",
    "- формулировка модели трехслойного перцептрона. Имеется в виду только один скрытый слой; +\n",
    "- формулировка функции ошибки; +\n",
    "- формулировка метрики (метрик); +\n",
    "- формулировка цикла оптимизации параметров. +\n",
    "\n",
    "#### Визуализация в решении:\n",
    "- распределение признаков; +\n",
    "- распределение целевой переменной; +\n",
    "- отдельные экземпляры выборки в виде изображений; +\n",
    "- эволюция функции ошибки по ходу обучения; +\n",
    "- эволюция метрики(метрик) по ходу обучения +\n",
    "\n",
    "#### Выводы\n",
    "- вывод о достаточности или избыточности данных для оценки параметров модели\n",
    "- вывод о соотношении выразительности модели и ее обобщающей способности (наблюдаются ли явления переобучения или недообучения).\n",
    "\n",
    "Примечание:<br />\n",
    "Реализация перцептрона и других составляющих исследования может быть написана только с использованием библиотеки Numpy или scipy. Решения с использованием библиотек автоматического вычисления градиентов не засчитываются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные данные\n",
    "\n",
    "Исходные данные можно скачать [по этой ссылке](https://www.dropbox.com/s/y6ar7i7mb6fvoed/mnist.npz). Набор данных MNIST поставляется в различных вариантах. В варианте, доступном по приведенной ссылке, чтение исходных данных может быть выполнено следующим образом:\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "mnist = np.load('mnist.npz')\n",
    "x_train = mnist['x_train']\n",
    "y_train = mnist['y_train']\n",
    "x_test = mnist['x_test']\n",
    "y_test = mnist['y_test']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многослойный перцептрон\n",
    "\n",
    "Напомним, мы задаем мнолослойный перцептрон как сложную функцию, в которой используются линейные операции и поточечные нелинейные преобразования. Если входные данные (признаковое описание объекта) заданы вектором $x$, то функция перцептрона с одним скрытым слоем выглядит следующим образом:\n",
    "$$\n",
    "F(x) = \\Psi\\left(\\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\\cdot\\theta_2 + b_2\\right),\n",
    "$$\n",
    "где $x$ имеется в виду без дополнительного единичного признака; $\\phi$ - функция активации скрытого слоя; $\\Psi$ - функция активации выходного слоя перцептрона.\n",
    "\n",
    "Напомним также, что в задаче жесткой многоклассовой классификации на $K$ классов допустим вариант формулировки модели, такой что:\n",
    "- количество признаков целевой переменной совпадает с количеством классов $K$;\n",
    "- в качестве функции активации $\\Psi$ может использоваться `softmax`:\n",
    "$$\n",
    "\\Psi(h_i) = \\frac{e^{h_i}}{\\sum_{j=1}^{K}{e^{h_j}}}\n",
    "$$\n",
    "- в качестве функции потерь может использоваться перекрестная энтропия в многоклассовом варианте (приведено в записи для одного объекта):\n",
    "$$\n",
    "{\\mathscr{L}}\\left(\\hat{y},y\\right) = -\\sum_{j=1}^{K}{y_j*ln\\left(\\hat{y}_j\\right)},\n",
    "$$\n",
    "где $\\hat{y}=F(x)$\n",
    "\n",
    "В своем решении вы никак не ограничены в выборе функций активации $\\phi$ или $\\Psi$. Однако есть некоторые устоявшиеся практики применения функций `ReLU, sigmoid, tanh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Особенности реализации функции `softmax`\n",
    "Несложно заметить, что как в числителе, так и в знаменателе функции `softmax` стоит экспонента некоторого числа. При этом следует понимать, что разрядность чисел с плавающей точкой `float32`, `float64` и даже `float128` не бесконечны. Свойства экспоненты таковы, что, например, для переполнения разрядности чисел `float64` (максимум  $\\sim1.78*10^{308}$) достаточно показателя, превышающего 710, что совсем немного. Поэтому в случае практической реализации функции `softmax` имеет смысл предусмотреть случаи, когда аргументы экспоненты велики или, наоборот, слишком малы.\n",
    "\n",
    "В этом ДЗ кроме прочих заданий вам нужно реализовать вычислительно стабильную версию `softmax`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Особенности вычисления градиента функции потерь\n",
    "\n",
    "В этом домашнем задании, также как и в ДЗ№1 предлагается реализовывать функцию потерь и отдельные вычислительные блоки перцептрона наследующими `Differentiable` для общности восприятия этих модулей как дифференцируемых по своим аргументам. По желанию можно вычислить градиент функции потерь по параметрам модели вручную (и далее реализовать его в коде), однако предпочитаемым способом будет реализация градиента каждого из вычислительных блоков по аргументу в методе `backward()` и использование этого результата в обобщенном виде, без упрощения. Этот вариант вычисления градиента функции потерь по параметрам модели называется \"backpropagation\" (\"метод обратного распространения ошибки\" или \"метод обратной волны\" у разных авторов).\n",
    "\n",
    "Нелишним будет напомнить, что в некоторых случаях для вычисления компоненты градиента необходимо хранить значения, полученные на этапе вычисления функции $F(x)$. В вашем решении это может быть устроено по-разному. Но для тех, кто хочет придерживаться предложенного шаблона, введен атрибут `state` класса `Differentiable`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Решение задачи 2</h1></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические сведения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая постановка задачи\n",
    "В данном задании требуется реализовать модель *трехслойного перцептрона*. В этом случае подразумевается, что первым слоем будет слой входных данных, затем один скрытый, который переходит в слой с ответом нашей модели.\n",
    "\n",
    "Задача связана с *классификацией* картинок из датасета **MNIST**. Требуется настроить алгоритм, который будет оптимально каждой картинке 28х28 ставить в соответствие некоторое число, которое на ней изображено.\n",
    "\n",
    "В общем виде, многослойный перцептрон можно определить следующим образом:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "    h_1 = \\psi_1(\\theta_1^T \\cdot \\phi_1(x))\n",
    "    \\\\\n",
    "    h_2 = \\psi_2(\\theta_2^T  \\cdot \\phi_2(h_1))\n",
    "    \\\\\n",
    "    \\vdots\n",
    "    \\\\\n",
    "    h_k = \\psi_k(\\theta_k^T \\cdot \\phi_k(h_{k-1}))\n",
    "    \\\\\n",
    "    y = \\psi_{k+1}(\\theta_{k+1}^T \\cdot \\phi_{k+1}(h_k))\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "где $x$ - объект (в нашем случае, это картинка с числом), $\\phi_i$ - basic function (фактически, некоторые преобразования над данными, например, нормировка), $\\theta_i$ - матрица параметров, по которым будет происходить оптимизация, $\\psi_i$ - activation function (какая-то нелинейная функция, для того чтобы $y$ задававал в итоге нелинейное отображение), $y$ - предсказание целевой метки (то есть для данной задачи - это предположительное число на картинке)\n",
    "\n",
    "Либо же в более человеческом виде:\n",
    "$$\n",
    "y = y(h_k(h_{k-1}(h_{k-2}(...h_1(x)))))\n",
    "$$\n",
    "\n",
    "То есть многослойный перцептрон - это всего лишь сложная функция.\n",
    "\n",
    "В нашей задаче:\n",
    "- функция имеет вид: $F(x) = \\Psi\\left(\\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\\cdot\\theta_2 + b_2\\right)$\n",
    "\n",
    "\n",
    "- $X$ - это множество векторов из $R^{784}$, то есть это \"плоское\" представление матриц 28х28 (то есть каждая строка этой матрицы конкатенируется с предыдущей и в итоге получается вектор размера 784).\n",
    "\n",
    "\n",
    "- $Y$ - one-hot вектор длиной 10, где единица стоит на месте с координатой истинной метки, а предсказанием алгоритма является вектор из вероятнотстей принадлежности каждому клаассу. Далее определим, каким образом получить эти самые вероятности\n",
    "\n",
    "\n",
    "Очень упрощенно, скорее с точностью до схемы, но не до чисел, нашу модель можно изобразить следующим образом (хотя реализация ниже позволяет использовать любое количество слоев):\n",
    "\n",
    "<img src=https://ljvmiranda921.github.io/assets/png/cs231n-ann/archi.png>\n",
    "\n",
    "## Функция активации на выходном слое и функция потерь\n",
    "`SoftMax` - обобщение сигмоида на многоклассовую классификацию. Так как хочется интерпретировать ответ алгоритма как вероятность, то `SoftMax` с этим отлично справляется, так как определяется следующим образом:\n",
    "$$\n",
    "y_{pred} = \n",
    "\\begin{bmatrix} \n",
    "P(t=0 | \\mathbf{z}) \\\\\n",
    "\\vdots \\\\\n",
    "P(t=9 | \\mathbf{z}) \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix} \n",
    "\\varsigma(\\mathbf{z})_0 \\\\\n",
    "\\vdots \\\\\n",
    "\\varsigma(\\mathbf{z})_9 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\frac{1}{\\sum_{d=0}^9 e^{z_d}}\n",
    "\\begin{bmatrix} \n",
    "e^{z_0} \\\\\n",
    "\\vdots \\\\\n",
    "e^{z_9} \\\\\n",
    "\\end{bmatrix}\n",
    "$$, \n",
    "где $\\varsigma(z)_c  := \\frac{e^{z_c}}{\\sum_{d=0}^9 e^{z_d}}$\n",
    "\n",
    "Также *hack* на тему того, как избегать переполнения float64, да и других типов:  `Softmax(x) == Softmax(x - const)`\n",
    "\n",
    "\n",
    "Нам потребуется найти производную `Cross-entropy` по аргументу `Softmax`, это можно сделать следующим образом:\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial \\xi}{\\partial z_i} & = - \\sum_{j=1}^C \\frac{\\partial t_j \\log(y_j)}{\\partial z_i}{} \n",
    "= - \\sum_{j=1}^C t_j \\frac{\\partial \\log(y_j)}{\\partial z_i} \n",
    "= - \\sum_{j=1}^C t_j \\frac{1}{y_j} \\frac{\\partial y_j}{\\partial z_i} \\\\\n",
    "& = - \\frac{t_i}{y_i} \\frac{\\partial y_i}{\\partial z_i} - \\sum_{j \\neq i}^C \\frac{t_j}{y_j} \\frac{\\partial y_j}{\\partial z_i}\n",
    "= - \\frac{t_i}{y_i} y_i (1-y_i) - \\sum_{j \\neq i}^C \\frac{t_j}{y_j} (-y_j y_i) \\\\\n",
    "& = - t_i + t_i y_i + \\sum_{j \\neq i}^C t_j y_i = - t_i + \\sum_{j = 1}^C t_j y_i\n",
    "= -t_i + y_i \\sum_{j = 1}^C t_j \\\\\n",
    "& = y_i - t_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Также на *backward-проходе* нам предстоит уметь вычислять производную `Softmax`-a по параметрам. Формально, это можно сделать следюущим образом:\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{если} \\; i = j :& \\frac{\\partial y_i}{\\partial z_i} = \\frac{\\partial \\frac{e^{z_i}}{\\Sigma_{0-9}}}{\\partial z_i} = \\frac{e^{z_i}\\Sigma_{0-9} - e^{z_i}e^{z_i}}{\\Sigma_{0-9}^2} = \\frac{e^{z_i}}{\\Sigma_{0-9}}\\frac{\\Sigma_{0-9} - e^{z_i}}{\\Sigma_{0-9}} = \\frac{e^{z_i}}{\\Sigma_{0-9}}(1-\\frac{e^{z_i}}{\\Sigma_{0-9}}) =  y_i (1 - y_i)\\\\\n",
    "\\text{если} \\; i \\neq j :& \\frac{\\partial y_i}{\\partial z_j} = \\frac{\\partial \\frac{e^{z_i}}{\\Sigma_{0-9}}}{\\partial z_j} = \\frac{0 - e^{z_i}e^{z_j}}{\\Sigma_{0-9}^2} = -\\frac{e^{z_i}}{\\Sigma_{0-9}} \\frac{e^{z_j}}{\\Sigma_{0-9}} = -y_i y_j\n",
    "\\end{split}\n",
    "$$, \n",
    "где $\\Sigma_{0-9} := \\sum\\limits_{d=0}^{9} e^{z_{d}}$\n",
    "\n",
    "Так как ответ алгоритма воспринимается как верооятность, то логичным будет максимизировать правдоподобие. По аналогии с тем, как выводится `logloss` для бинарной классификации, можно вывести общий вид этой функции потерь, который и будет именоваться, как `Cross-entropy`:\n",
    "$$\n",
    "L(Y,Y_{pred}) = \\sum_{i=1}^n l(\\mathbf{y}_i,\\mathbf{y}^{pred}_i) = -\\sum_{i=1}^n \\sum_{d=0}^{9} y_{id} \\cdot \\log( y^{pred}_{id})\n",
    "$$,\n",
    "где $n$ - размер минибатча.\n",
    "\n",
    "## Описание метода оптимизации\n",
    "В данной реализации полносвязной нейронной сети будем использовать градиентную оптимизацию, а именно `Nesterov momentum`. Это модификация стохастического градиентного спуска, которая формально реализуется следующим образом:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "    m_t = m_{t - 1} \\cdot \\beta + \\nabla_{\\theta} L(\\theta_{t-1} + m_{t - 1} \\cdot \\beta) \\cdot (1 - \\beta)\n",
    "    \\\\\n",
    "    \\theta_t = \\theta_{t-1} - \\alpha \\cdot m_t\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Для шага оптимизации  надо знать значение импульса для каждого параметра, а как следствие уметь посчитать градиент по параметру. Для этого используют `back propagation` - метод вычисления градиента лосса по параметрам нейронной сети.<br>\n",
    "\n",
    "Для начала заметим, что параметрами в нашем перцептроне являются $\\theta_2, \\theta_1, b_2, b_1$. Таким образом, нам надо научиться оптимально считать $\\frac{\\partial L}{\\partial \\theta_2}, \\frac{\\partial L}{\\partial \\theta_1}, \\frac{\\partial L}{\\partial b_2}, \\frac{\\partial L}{\\partial b_1}$, чтобы делать шаг градиентного спуска для каждого из параметров.\n",
    "\n",
    "Введем следующие обозначения:\n",
    "$$\n",
    "a_2 = \\Psi\\left(\\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\\cdot\\theta_2 + b_2\\right)\n",
    "\\\\\n",
    "o_2 = \\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\\cdot\\theta_2 + b_2\n",
    "\\\\\n",
    "a_1 = \\phi\\left( {x}\\cdot\\theta_1 + b_1 \\right)\n",
    "\\\\\n",
    "o_1 = {x}\\cdot\\theta_1 + b_1 \n",
    "$$\n",
    "Причем, в таких обозначениях, $a_i$ - по сути input на $i+1$ слой, а o_i - output на i линейном слое.\n",
    "\n",
    "Теперь остается заметить, что:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial a_2} \\frac{\\partial a_2}{\\partial o_2} \\frac{\\partial o_2}{\\partial b_2} = o_2 - y\n",
    "\\\\\n",
    "\\frac{\\partial L}{\\partial \\theta_2} = \\frac{\\partial L}{\\partial a_2} \\frac{\\partial a_2}{\\partial o_2} \\frac{\\partial o_2}{\\partial \\theta_2} = (o_2 - y) \\cdot a_1\n",
    "\\\\\n",
    "\\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial o_2} \\frac{\\partial o_2}{\\partial a_1} \\frac{\\partial a_1}{\\partial o_1} \\frac{\\partial o_1}{\\partial b_1} = \\frac{\\partial L}{\\partial o_2} \\cdot \\theta_2 \\cdot \\phi(o_1) \\cdot (1 - \\phi(o_1))\n",
    "\\\\\n",
    "\\frac{\\partial L}{\\partial \\theta_1} = \\frac{\\partial L}{\\partial o_2} \\frac{\\partial o_2}{\\partial a_1} \\frac{\\partial a_1}{\\partial o_1} \\frac{\\partial o_1}{\\partial \\theta_1} = \\frac{\\partial L}{\\partial o_2} \\cdot \\theta_2 \\cdot \\phi(o_1) \\cdot (1 - \\phi(o_1)) \\cdot X\n",
    "\\end{equation}\n",
    "$$\n",
    "где $\\phi(x)$ - сигмоид (для наглядности производной). \n",
    "\n",
    "Какой мы можем сделать из этого всего вывод? А такой, что на `forward-pass` следует кэшировать входные значения на каждом слое функции, а для того, чтобы подсчитать градиент по параметрам на слое $t$, надо также знать $\\frac{\\partial L}{\\partial o_{t+1}},$ для того чтобы не пересчитывать по 100 раз (а лишь один раз) производные на \"верхних слоях\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подгрузка основнвных модулей\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Подгрузка данных с разделением на обучаующую и тестовую выборки\n",
    "mnist = np.load('./mnist.npz')\n",
    "\n",
    "x_train = mnist['x_train']\n",
    "y_train = mnist['y_train']\n",
    "\n",
    "x_test = mnist['x_test']\n",
    "y_test = mnist['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация данных\n",
    "Для начала посмотрим, как буквально выглядят данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM = 5\n",
    "\n",
    "fig, ax = plt.subplots(NUM, NUM, figsize=(10, 10))\n",
    "plt.subplots_adjust(left=-0.2, bottom=-0.3)\n",
    "\n",
    "for i in range(NUM**2):\n",
    "    rand_num = np.random.randint(0, x_train.shape[0])\n",
    "    \n",
    "    ax[i // NUM, i % NUM].imshow(x_train[rand_num],)\n",
    "    ax[i // NUM, i % NUM].set_title(f'IMAGE LABEL: {y_train[rand_num]}')\n",
    "    ax[i // NUM, i % NUM].set_xticks([])\n",
    "    ax[i // NUM, i % NUM].set_yticks([])\n",
    "    ax[i // NUM, i % NUM].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape тренировочной выборки: (60000, 28, 28)\n",
      "shape тестовой выборки: (10000, 28, 28)\n",
      "shape целевой метки на тренировке: (60000,)\n",
      "shape целевой метки на тесте: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape тренировочной выборки: {x_train.shape}\")\n",
    "print(f\"shape тестовой выборки: {x_test.shape}\")\n",
    "print(f\"shape целевой метки на тренировке: {y_train.shape}\")\n",
    "print(f\"shape целевой метки на тесте: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, данные у нас представлены в виде 70000 матриц 28х28, причем значения в этих матрицах лежат в промежутке [0, 255].\n",
    "Так как по условию задачи требуется реализовать полносвязную нейронную сеть, то на входной слой следует подавать вектор признаков, который является плоским представлением матриц 28х28 (то есть каждая строка этой матрицы конкатенируется с предыдущей и в итоге получатеся вектор размера 784).\n",
    "\n",
    "Также, так как мы решаем задачу многоклассовой классификации, оптимизируя Cross-Entropy как функцию потерь (и используя Softmax, который возвращает вектор из вероятностей), то целевая метка должна быть не числом, а One-Hot вектором. \n",
    "\n",
    "Вдобавок, так как оптимизация градиентная, то нормализуем данные на отрезок [0, 1] по формуле $x := \\frac{x - x_{min}}{x_{max} - x_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_normal(data):\n",
    "    assert data.ndim == 2\n",
    "    \n",
    "    min_value = data.min(axis=0)\n",
    "    max_value = data.max(axis=0)\n",
    "    \n",
    "    return (data - min_value) / (max_value - min_value + 1e-100)\n",
    "\n",
    "\n",
    "def make_flat(data):\n",
    "    flat_data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    assert flat_data.shape[1] == 784\n",
    "    return flat_data\n",
    "\n",
    "\n",
    "def make_one_hot(y, length=10):\n",
    "    assert len(y.shape) == 1\n",
    "    \n",
    "    one_hot_y = np.empty(shape=(y.shape[0], length))\n",
    "    \n",
    "    for ind, obj_label in enumerate(y):\n",
    "        one_hot_y[ind] = np.array([1 if obj_label == i else 0 for i in range(length)])\n",
    "        \n",
    "    return one_hot_y\n",
    "\n",
    "\n",
    "def make_train_test(X, y, train_size=0.8):\n",
    "    perm = np.random.permutation(range(len(X)))\n",
    "    train_indx = perm[:int(train_size * len(X))]\n",
    "    test_indx = perm[int(train_size * len(X)):]\n",
    "    \n",
    "    return (\n",
    "        X[train_indx], X[test_indx],\n",
    "        y[train_indx], y[test_indx],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat для x\n",
    "x_train_flat = make_flat(x_train)\n",
    "x_test_flat = make_flat(x_test)\n",
    "\n",
    "# one_hot для y\n",
    "y_train_one_hot = make_one_hot(y_train)\n",
    "y_test_one_hot = make_one_hot(y_test)\n",
    "\n",
    "# здесь можно не париться о data leak'е, так как max = 255, min = 0 (почти наверное)\n",
    "x_train = make_normal(x_train)\n",
    "x_test = make_normal(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Табличная предобработка\n",
    "\n",
    "Созадим `DataFrame` для train и test выборок, чтобы в дальнейшем произвести манипуляции непосредственно на обеих выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, pixel_1 to target\n",
      "dtypes: float64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "columns_train = chain((f\"pixel_{i}\" for i in range(1, x_train.shape[1] + 1)), ('target',))\n",
    "\n",
    "df_train = pd.DataFrame(\n",
    "    np.concatenate((x_train, y_train[:, np.newaxis]), axis=1),\n",
    "    columns=columns_train,\n",
    ")\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, pixel_1 to target\n",
      "dtypes: float64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "columns_test = chain((f\"pixel_{i}\" for i in range(1, x_test.shape[1] + 1)), ('target',))\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "    np.concatenate((x_test, y_test[:, np.newaxis]), axis=1),\n",
    "    columns=columns_test\n",
    ")\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество признаков с пустыми значениями на train: 0\n",
      "количество признаков с пустыми значениями на test: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'количество признаков с пустыми значениями на train: {(df_train.isna().sum() > 0).sum()}')\n",
    "print(f'количество признаков с пустыми значениями на test: {(df_test.isna().sum() > 0).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление фиктивных признаков\n",
    "Посмотрим, есть ли среди признаков такие, что они имеют одно и то же значение на всех объектах. Соответственно, такие признаки мы будем искать на train, а затем удалим ровно их же на test, чтобы не произошло data leak'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_pix(dataframe):\n",
    "    new = dataframe.copy()\n",
    "    deleted = []\n",
    "    \n",
    "    for column in dataframe: \n",
    "        if dataframe[column].min() == dataframe[column].max():\n",
    "            deleted.append(column)\n",
    "            new.drop(column, axis=1, inplace=True)\n",
    "            \n",
    "    return new, deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_wo_constant, train_feature_deleted = remove_constant_pix(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 718)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wo_constant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_wo_constant = df_test.drop(train_feature_deleted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 718)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_wo_constant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальная предобработка\n",
    "Наконец, разобьем данные на три группы:\n",
    "- train - данные для обучения\n",
    "- validataion - данные для оценки работы модели во время обучения\n",
    "- test - \"скрытые\" от нас данные, для самой финальной оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train = df_train_wo_constant.drop('target', axis=1)\n",
    "X_tr, X_val, y_tr, y_val = make_train_test(prepared_train.values, y_train_one_hot, train_size=0.8)\n",
    "\n",
    "X_test = df_test_wo_constant.drop('target', axis=1)\n",
    "y_tset = y_test_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 717)\n",
      "(12000, 717)\n",
      "(10000, 717)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация модели\n",
    "## Описание основных классов\n",
    "Далее будут реализованы следующие классы:\n",
    "- `Module` - абстрактный базовый класс для всех модулей нейронной сети.\n",
    "\n",
    "- `Loss` - абстрактный базовый класс для всех функционалов ошибки.\n",
    "\n",
    "- `CrossEntropy` - класс для описания функционала ошибки, а именно CrossEntropy.\n",
    "\n",
    "- `Linear` - класс, описывающий линейную часть модели.\n",
    "\n",
    "- `ReLu` - класс для ReLu функции активации.\n",
    "\n",
    "- `Softmax` - класс для функции активации Softmax (описывался выше)\n",
    "\n",
    "- `Sequential` - класс для аггрегации слоев сети. По сути можно рассматривать как некоторый контейнер с архитектурой нейронной сети.\n",
    "\n",
    "Более подробное описание можно увидеть в документации к классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(ABC):\n",
    "    def __init__(self):\n",
    "        self.input_grad = None  # необходим для хранения градиента по input на данном модуле\n",
    "        self.input = None  # необходим для кэширования input на forward-pass\n",
    "        self.output = None # необходим для кэширования output на forward-pass\n",
    "        self.has_parameters = False  # требуется поставить True у линейного слоя\n",
    "        self.train = True  # отображает, находится ли модель в состоянии тренировки или в состоянии теста\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, input_):\n",
    "        '''\n",
    "        Абстрактный метод, \n",
    "        который возвращает значение соответствующего модуля по input_  \n",
    "        \n",
    "        Args:\n",
    "            input_: входные данные для этого модуля\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, output_grad):\n",
    "        '''\n",
    "        Абстрактный метод, \n",
    "        который возвращает значение градиента Loss'а\n",
    "        по input на этого модуля.\n",
    "        \n",
    "        Args:\n",
    "            output_grad: градиент Loss'а по output этого модуля\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def train_(self):\n",
    "        '''\n",
    "        Переводит модуль в режим тренировки\n",
    "        '''\n",
    "        self.train = True\n",
    "        \n",
    "    def evaluate_(self):\n",
    "        '''\n",
    "        Переводит модуль в режим вычисления на валидационных данных\n",
    "        '''\n",
    "        self.train = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Module\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(ABC):\n",
    "    def __init__(self):\n",
    "        self.input_grad = None  # необходим для хранения градиента по input на данном модуле\n",
    "        self.input = None  # необходим для сохранения input на forward-pass\n",
    "        self.train = True  # отображает, находится ли модель в состоянии тренировки или в состоянии теста \n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, y_pred, y_true):\n",
    "        '''\n",
    "        Абстрактный метод, \n",
    "        который вычисляет значение лосса по истинным значениям\n",
    "        и предсказанным моделью\n",
    "        \n",
    "        Args:\n",
    "            y_pred: предсказанные значения\n",
    "            y_true: истинные значения\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self, y_true):\n",
    "        '''\n",
    "        Абстрактный метод, который должен возващать\n",
    "        градиент лосса по входу, то есть про предсказанным значениям\n",
    "        \n",
    "        Args:\n",
    "            y_pred: предсказанные значения\n",
    "            y_true: истинные значения\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def train_(self):\n",
    "        '''\n",
    "        Переводит лосс в режим треинровки\n",
    "        '''\n",
    "        self.train = True\n",
    "        \n",
    "    def evaluate_(self):\n",
    "        '''\n",
    "        Переводит лосс в режим вычисления на валидационных данных без кэшироваиня\n",
    "        '''\n",
    "        self.train = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        Просто для красивого print'а\n",
    "        '''\n",
    "        return \"Loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Loss):\n",
    "    # Реализация Cross-entropy\n",
    "    def __init__(self):\n",
    "        super(CrossEntropy, self).__init__()\n",
    "        \n",
    "    def __call__(self, y_pred, y_true):\n",
    "        return self.forward(y_pred, y_true)\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == y_true.ndim == 2, \"предсказывается матрица, у которой каждая строка - предсказание для одного объекта\"\n",
    "        \n",
    "        if self.train:  # следует кэшировать только на тренировке\n",
    "            self.input = y_pred  # для консинстентности стиля, сохраним y_pred в self.input\n",
    "        \n",
    "        log_pred = np.log(y_pred)\n",
    "        entropy = np.sum(y_true * log_pred, axis=1)\n",
    "        avg_entropy = entropy.mean()\n",
    "        \n",
    "        return np.negative(avg_entropy)\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        assert y_true.shape == self.input.shape, \"self.input и y_pred должны быть одноразмерны\"\n",
    "        \n",
    "        self.input_grad = np.negative(np.divide(y_true, self.input))\n",
    "        \n",
    "        return self.input_grad\n",
    "        \n",
    "    def __repr__(self):\n",
    "        # просто для красивого printing'а\n",
    "        return \"Cross-Entropy\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, fit_intercept=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.has_parameters = True\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # вроде бы нормальный способ инициализации весов для такой маленькой сетки (refers to LeNet)\n",
    "        stdv = 1./np.sqrt(in_features)\n",
    "        self.W = np.random.uniform(-stdv, stdv, size=(out_features, in_features))\n",
    "        self.grad_W = np.zeros_like(self.W)\n",
    "        self.momentum_W = np.zeros_like(self.W)\n",
    "                \n",
    "        if fit_intercept:  # если у линейного слоя есть bias:\n",
    "            self.b = np.random.uniform(-stdv, stdv, size=(out_features))\n",
    "            self.grad_b = np.zeros_like(self.b)\n",
    "            self.momentum_b = np.zeros_like(self.b)\n",
    "    \n",
    "    def __call__(self, input_):\n",
    "        return self.forward(input_)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        assert input_.ndim == 2, \"input_ линейной модели должен быть размерности 2\"\n",
    "        \n",
    "        if self.train:  # следует кэшировать только на тренировке\n",
    "            self.input = input_\n",
    "            self.output = self.input @ self.W.T + self.b\n",
    "        \n",
    "        assert self.output.shape == (self.input.shape[0], self.W.shape[0]), \"линейная модель должна возврващать матрицу\" \\\n",
    "                                                                            \"размера (n_samples x out_features)\"\n",
    "        return input_ @ self.W.T + self.b\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        assert output_grad.ndim == 2\n",
    "        \n",
    "        output_grad_tr = output_grad[:, np.newaxis]\n",
    "        input_tr = self.input[:, np.newaxis]\n",
    "        W_tr = np.repeat(self.W[None], repeats=output_grad.shape[0], axis=0)\n",
    "        \n",
    "        \n",
    "        input_grad_tr = output_grad_tr @ W_tr\n",
    "        \n",
    "        self.input_grad = np.squeeze(input_grad_tr) \n",
    "        \n",
    "        grad_W_wo_sum = output_grad_tr.reshape((self.input.shape[0], output_grad.shape[1], 1)) @ input_tr\n",
    "        \n",
    "        self.grad_W = np.sum(grad_W_wo_sum, axis=0)\n",
    "        self.grad_b = output_grad\n",
    "        \n",
    "        assert self.input_grad.ndim == 2 and self.grad_W.ndim == 2 and self.grad_W.shape == self.W.shape\n",
    "        return self.input_grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.grad_W.fill(0)\n",
    "        self.grad_b.fill(0)\n",
    "    \n",
    "    @property\n",
    "    def W_(self):\n",
    "        '''\n",
    "        Getter для матрицы весов линейного слоя\n",
    "        '''\n",
    "        return self.W\n",
    "    \n",
    "    @W_.setter\n",
    "    def W_(self, new_W):\n",
    "        '''\n",
    "        Setter для матрицы весов линейного слоя\n",
    "        '''\n",
    "        self.W = new_W\n",
    "        \n",
    "    @property\n",
    "    def b_(self):\n",
    "        '''\n",
    "        Getter для 'bias'a линейного слоя\n",
    "        '''        \n",
    "        return self.b\n",
    "    \n",
    "    @b_.setter\n",
    "    def b_(self, new_b):\n",
    "        '''\n",
    "        Setter для 'bias'a линейного слоя\n",
    "        '''               \n",
    "        self.b = new_b\n",
    "    \n",
    "    @property\n",
    "    def grad_W_(self):\n",
    "        '''\n",
    "        Getter для градиента лосса по матрице весов.\n",
    "        '''\n",
    "        return self.grad_W\n",
    "    \n",
    "    @property\n",
    "    def grad_b_(self):\n",
    "        '''\n",
    "        Getter для градиента лосса по 'bias'у\n",
    "        '''\n",
    "        return self.grad_b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # для красивого printing'а\n",
    "        return f\"Linear: {self.in_features} -> {self.out_features}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLu, self).__init__()\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        assert input_.ndim == 2, \"input_ReLu должен быть размерности 2\"\n",
    "        \n",
    "        if self.train:  # следует кэшировать только на тренировке\n",
    "            self.input = input_\n",
    "        \n",
    "        return np.maximum(input_, 0)\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        self.input_grad = np.multiply(output_grad, self.input > 0)\n",
    "        \n",
    "        return self.input_grad\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # для красивого printing'а\n",
    "        return \"ReLu\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Module):\n",
    "    def __init__(self):\n",
    "        super(Softmax, self).__init__()\n",
    "    \n",
    "    def __call__(self, input_):\n",
    "        return self.forward(input_)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        input_transformed = np.exp(input_ - np.max(input_, axis=1)[:, np.newaxis])\n",
    "        \n",
    "        if self.train:  # следует кэшировать только на тренировке\n",
    "            self.input = input_\n",
    "            self.output = np.divide(input_transformed, np.sum(input_transformed, axis=1)[:, np.newaxis])\n",
    "        \n",
    "        return np.divide(input_transformed, np.sum(input_transformed, axis=1)[:, np.newaxis])\n",
    "    \n",
    "    @staticmethod\n",
    "    def jacobian(x):\n",
    "        '''\n",
    "        Возвращает якобиан Softmax'a, который выражается через сам Softmax.\n",
    "        '''\n",
    "        x = x.reshape(-1,1)\n",
    "        return np.diagflat(x) - np.dot(x, x.T)\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        output = self.forward(self.input)[:, np.newaxis]\n",
    "        jacob = np.squeeze(np.apply_along_axis(Softmax.jacobian, axis=2, arr=output))\n",
    "        \n",
    "        \n",
    "        output_grad_tr = output_grad[:, np.newaxis]\n",
    "        self.input_grad = np.squeeze(output_grad_tr @ jacob)\n",
    "        \n",
    "        return self.input_grad\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Softmax\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizationModeError(Exception):\n",
    "    def __init__(self):\n",
    "        super(OptimizationModeError, self).__init__\n",
    "\n",
    "\n",
    "class Sequential(Module):\n",
    "    def __init__(self, optimization_mode='Momentum'):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.modules = []\n",
    "        self.optimization_mode = optimization_mode\n",
    "        \n",
    "    def __call__(self, input_):\n",
    "        return self.forward(input_)\n",
    "    \n",
    "    def add(self, module):\n",
    "        '''\n",
    "        Метод для добавления слоя\n",
    "        \n",
    "        Args:\n",
    "            module: слой, который требуется добавить\n",
    "        '''\n",
    "        self.modules.append(module)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        output = input_\n",
    "        for module in self.modules:\n",
    "            output = module.forward(output)\n",
    "        \n",
    "        if self.train:  # следует кэшировать только на тренировке\n",
    "            self.input = input_\n",
    "            self.output = output\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        '''\n",
    "        Делаем backward на каждом слое нейронной сети\n",
    "        \n",
    "        Args:\n",
    "            output_grad: градиент лосса по input'у лосса\n",
    "        '''\n",
    "        \n",
    "        self.grad_input = output_grad\n",
    "        for i in range(len(self.modules) - 1, 0, -1):\n",
    "            self.grad_input = self.modules[i].backward(self.grad_input)\n",
    "        \n",
    "        self.grad_input = self.modules[0].backward(self.grad_input)\n",
    "        \n",
    "        return self.grad_input\n",
    "    \n",
    "    \n",
    "    def zero_grad(self):\n",
    "        '''\n",
    "        Обнуление градиентов по параметрам\n",
    "        '''\n",
    "        for module in self.modules:\n",
    "            if module.has_parameters:\n",
    "                module.zero_grad()\n",
    "    \n",
    "    @property\n",
    "    def gradients(self):\n",
    "        '''\n",
    "        Getter для листа параметров\n",
    "        '''\n",
    "        return [[module.W_, module.b_] for module in self.modules if module.has_parameters]\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        '''\n",
    "        Getter для листа градиентов\n",
    "        '''\n",
    "        return [[module.grad_W_, module.grad_b_] for module in self.modules if module.has_parameters]\n",
    "    \n",
    "    def train_mode(self):\n",
    "        self.train_()\n",
    "        for module in self.modules:\n",
    "            module.train_()\n",
    "            \n",
    "    def evaluate_mode(self):\n",
    "        self.evaluate_()\n",
    "        for module in self.modules:\n",
    "            module.evaluate_()\n",
    "    \n",
    "    def optimization(self, learning_rate, batch_size, beta=0.9):\n",
    "        '''\n",
    "        Метод, реализующий шаг оптимизации.\n",
    "        Поддерживваются vanilla SGD и SGD + Momentum\n",
    "        \n",
    "        Args:\n",
    "            learning_rate: скорость обучения\n",
    "            \n",
    "        '''\n",
    "        if self.optimization_mode == 'SGD':\n",
    "            for module in self.modules:\n",
    "                if module.has_parameters:\n",
    "                    module_W = module.W_\n",
    "                    module_grad_W = module.grad_W_\n",
    "                    module.W_ = module_W - learning_rate * module_grad_W / batch_size\n",
    "\n",
    "                    if module.fit_intercept:\n",
    "                        module_b = module.b_\n",
    "                        module_grad_b = module.grad_b_\n",
    "                        module.b_ = module_b - learning_rate * module_grad_b / batch_size\n",
    "                        \n",
    "        elif self.optimization_mode == 'Momentum':\n",
    "            for module in self.modules:\n",
    "                if module.has_parameters:\n",
    "                    module_W = module.W_\n",
    "                    module_grad_W = module.grad_W_\n",
    "                    \n",
    "                    module.momentum_W = beta * module.momentum_W + (1 - beta) * module_grad_W \n",
    "                    module.W_ = module_W - learning_rate * module_grad_W / batch_size\n",
    "\n",
    "                    if module.fit_intercept:\n",
    "                        module_b = module.b_\n",
    "                        module_grad_b = module.grad_b_\n",
    "                        \n",
    "                        module.momentum_b = beta * module.momentum_b + (1 - beta) * module_grad_b\n",
    "                        module.b_ = module_b - learning_rate * module.momentum_b / batch_size\n",
    "                        \n",
    "                    else:\n",
    "                        raise OptimizationModeError('Unavailable Optimization')\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return ''.join([str(module) + '\\n\\t' for module in self.modules ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание и инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = X_tr.shape[1]\n",
    "HIDDEN = 128\n",
    "OUTPUT = y_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tАрхитектура модели полносвязной нейронной сети:\n",
      " \n",
      "\tLinear: 717 -> 128\n",
      "\tReLu\n",
      "\tLinear: 128 -> 10\n",
      "\tSoftmax\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "loss = CrossEntropy()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Linear(INPUT, HIDDEN))\n",
    "model.add(ReLu())\n",
    "model.add(Linear(HIDDEN, OUTPUT))\n",
    "model.add(Softmax())\n",
    "\n",
    "print(f\"\\tАрхитектура модели полносвязной нейронной сети:\\n \\n\\t{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "DATASET = (\n",
    "    ('train', (X_tr, y_tr)),\n",
    "    ('eval', (X_val, y_val)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 717)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_batches(X, y, batch_size):\n",
    "    '''\n",
    "    Генератор батчей.\n",
    "        \n",
    "    Args:\n",
    "        X: матрица объектов\n",
    "        y: вектор целевых меток\n",
    "        batch_size: размер батча\n",
    "    '''\n",
    "    assert len(X) == len(y)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    perm = np.random.permutation(len(X))\n",
    "    full_batch_quantity = len(perm) // batch_size\n",
    "   \n",
    "    perm = list(perm)\n",
    "    for i in range(full_batch_quantity):\n",
    "        \n",
    "        batch_inds = []\n",
    "        batch_inds.extend(perm[(i*batch_size):((i+1)*batch_size)])\n",
    "    \n",
    "        assert len(batch_inds) == batch_size\n",
    "        yield (X[batch_inds], y[batch_inds])\n",
    "next(generate_batches(X_tr, y_tr, 100))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset, model, loss, batch_size, learning_rate=1e-2, epochs=100):\n",
    "    '''\n",
    "    Цикл обучения модели.\n",
    "    \n",
    "    Args:\n",
    "        dataset: объелиненеие тренировочной и валидационной выборок.\n",
    "        model: обучаемая модель\n",
    "        loss: минимизируемый функционал потерь\n",
    "        batch_size: размер батча\n",
    "        learning_rate: коэффициент скорости обучения\n",
    "        epochs: количетсво эпох для обучения\n",
    "    \n",
    "    '''\n",
    "    loss_history_train = []\n",
    "    loss_history_eval = []\n",
    "    \n",
    "    accuracy_history_train = []\n",
    "    accuracy_history_eval = []\n",
    "    \n",
    "    epoch_loss_train = []\n",
    "    epoch_loss_eval = []\n",
    "    \n",
    "    pbar = tqdm(total=epochs)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # каждую эпоху будем пробегать и по train, и по test\n",
    "        for data_type, data in dataset:            \n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            \n",
    "            if data_type == 'train':\n",
    "                # переходим в режим тренировки\n",
    "                model.train_mode()\n",
    "                \n",
    "                epoch_correct_train = 0\n",
    "                epoch_all_train = 0\n",
    "                for batch_X, batch_y in generate_batches(X, y, batch_size):\n",
    "                \n",
    "                    # обнуление градиента\n",
    "                    model.zero_grad()\n",
    "\n",
    "                    # forward-pass\n",
    "                    batch_y_pred = model(batch_X)\n",
    "            \n",
    "                    # преобразоваиня для вычисления accuracy\n",
    "                    max_proba = np.argmax(batch_y_pred, axis=1)\n",
    "                    one_hot_pred = make_one_hot(max_proba)\n",
    "                    epoch_correct_train += (one_hot_pred == batch_y).all(axis=1).sum()\n",
    "                    epoch_all_train += len(batch_y)\n",
    "            \n",
    "                    # вычисление лосса\n",
    "                    loss_value_train = loss(batch_y_pred, batch_y)\n",
    "                    epoch_loss_train.append(loss_value_train)\n",
    "        \n",
    "                    # backward-pass\n",
    "                    loss_grad = loss.backward(batch_y)\n",
    "                    model.backward(loss_grad)\n",
    "            \n",
    "                    # шаг оптимизации (дефолтно - Momentum)\n",
    "                    model.optimization(learning_rate, batch_size)\n",
    "            \n",
    "            elif data_type == 'eval':\n",
    "                # переходим в режим оценки \n",
    "                model.evaluate_mode()\n",
    "                \n",
    "                epoch_correct_eval = 0\n",
    "                epoch_all_eval = 0                \n",
    "                for batch_X, batch_y in generate_batches(X, y, batch_size):\n",
    "                    \n",
    "                    # forward-pass без кэша\n",
    "                    batch_y_pred = model(batch_X)\n",
    "                \n",
    "                    # преобразоваиня для вычисления accuracy\n",
    "                    max_proba = np.argmax(batch_y_pred, axis=1)\n",
    "                    one_hot_pred = make_one_hot(max_proba)\n",
    "                    epoch_correct_eval += (one_hot_pred == batch_y).all(axis=1).sum()\n",
    "                    epoch_all_eval += len(batch_y)\n",
    "                    \n",
    "                    # вычисление лосса\n",
    "                    loss_value_eval = loss(batch_y_pred, batch_y)\n",
    "                    epoch_loss_eval.append(loss_value_eval)\n",
    "                \n",
    "            \n",
    "        mean_loss_train = np.mean(epoch_loss_train)\n",
    "        mean_loss_eval = np.mean(epoch_loss_eval)\n",
    "        accuracy_train = epoch_correct_train / epoch_all_train\n",
    "        accuracy_eval = epoch_correct_eval / epoch_all_eval\n",
    "        \n",
    "        # обновление progress bar'а\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'cross-entropy': mean_loss_train,\n",
    "                          'accuracy': accuracy_train})\n",
    "        \n",
    "        accuracy_history_train.append(epoch_correct_train / epoch_all_train)  # добавляем accuracy на одной эпохе \n",
    "        loss_history_train.append(mean_loss_train)  # добавляем среднее за эпоху в историю\n",
    "        epoch_loss_train.clear()\n",
    "        \n",
    "        accuracy_history_eval.append(accuracy_eval)  # добавляем accuracy на одной эпохе \n",
    "        loss_history_eval.append(mean_loss_eval)  # добавляем среднее за эпоху в историю\n",
    "        epoch_loss_eval.clear()\n",
    "        \n",
    "    return loss_history_train, accuracy_history_train, loss_history_eval, accuracy_history_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [00:20<33:22, 20.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [00:20<33:22, 20.23s/it, cross-entropy=1.81, accuracy=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [00:40<32:50, 20.10s/it, cross-entropy=1.81, accuracy=0.628]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [00:40<32:50, 20.10s/it, cross-entropy=0.911, accuracy=0.82]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 3/100 [00:59<32:22, 20.02s/it, cross-entropy=0.911, accuracy=0.82]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 3/100 [00:59<32:22, 20.02s/it, cross-entropy=0.61, accuracy=0.857]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 4/100 [01:19<31:49, 19.89s/it, cross-entropy=0.61, accuracy=0.857]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 4/100 [01:19<31:49, 19.89s/it, cross-entropy=0.499, accuracy=0.875]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 5/100 [01:39<31:20, 19.80s/it, cross-entropy=0.499, accuracy=0.875]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 5/100 [01:39<31:20, 19.80s/it, cross-entropy=0.442, accuracy=0.884]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 6/100 [01:58<30:53, 19.72s/it, cross-entropy=0.442, accuracy=0.884]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 6/100 [01:58<30:53, 19.72s/it, cross-entropy=0.407, accuracy=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 7/100 [02:18<30:33, 19.71s/it, cross-entropy=0.407, accuracy=0.891]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 7/100 [02:18<30:33, 19.71s/it, cross-entropy=0.383, accuracy=0.895]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 8/100 [02:38<30:22, 19.81s/it, cross-entropy=0.383, accuracy=0.895]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 8/100 [02:38<30:22, 19.81s/it, cross-entropy=0.366, accuracy=0.9]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [02:58<30:03, 19.82s/it, cross-entropy=0.366, accuracy=0.9]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [02:58<30:03, 19.82s/it, cross-entropy=0.352, accuracy=0.903]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 10/100 [03:18<30:01, 20.02s/it, cross-entropy=0.352, accuracy=0.903]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 10/100 [03:18<30:01, 20.02s/it, cross-entropy=0.34, accuracy=0.906] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 11/100 [03:39<29:52, 20.14s/it, cross-entropy=0.34, accuracy=0.906]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 11/100 [03:39<29:52, 20.14s/it, cross-entropy=0.33, accuracy=0.908]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/100 [03:59<29:30, 20.12s/it, cross-entropy=0.33, accuracy=0.908]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/100 [03:59<29:30, 20.12s/it, cross-entropy=0.321, accuracy=0.91]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/100 [04:18<29:03, 20.04s/it, cross-entropy=0.321, accuracy=0.91]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/100 [04:18<29:03, 20.04s/it, cross-entropy=0.314, accuracy=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 14/100 [04:38<28:39, 20.00s/it, cross-entropy=0.314, accuracy=0.912]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 14/100 [04:38<28:39, 20.00s/it, cross-entropy=0.307, accuracy=0.914]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 15/100 [04:58<28:17, 19.97s/it, cross-entropy=0.307, accuracy=0.914]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 15/100 [04:58<28:17, 19.97s/it, cross-entropy=0.3, accuracy=0.916]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/100 [05:19<28:04, 20.05s/it, cross-entropy=0.3, accuracy=0.916]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/100 [05:19<28:04, 20.05s/it, cross-entropy=0.294, accuracy=0.918]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 17/100 [05:39<27:42, 20.04s/it, cross-entropy=0.294, accuracy=0.918]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 17/100 [05:39<27:42, 20.04s/it, cross-entropy=0.289, accuracy=0.919]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 18/100 [05:59<27:24, 20.06s/it, cross-entropy=0.289, accuracy=0.919]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|█▊        | 18/100 [05:59<27:24, 20.06s/it, cross-entropy=0.283, accuracy=0.92] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 19/100 [06:19<27:22, 20.28s/it, cross-entropy=0.283, accuracy=0.92]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 19/100 [06:19<27:22, 20.28s/it, cross-entropy=0.278, accuracy=0.922]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 20/100 [06:39<26:46, 20.08s/it, cross-entropy=0.278, accuracy=0.922]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 20/100 [06:39<26:46, 20.08s/it, cross-entropy=0.273, accuracy=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 21/100 [06:59<26:30, 20.13s/it, cross-entropy=0.273, accuracy=0.924]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|██        | 21/100 [06:59<26:30, 20.13s/it, cross-entropy=0.268, accuracy=0.925]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 22/100 [07:19<26:10, 20.13s/it, cross-entropy=0.268, accuracy=0.925]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 22/100 [07:19<26:10, 20.13s/it, cross-entropy=0.264, accuracy=0.926]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 23/100 [07:39<25:46, 20.08s/it, cross-entropy=0.264, accuracy=0.926]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 23/100 [07:39<25:46, 20.08s/it, cross-entropy=0.259, accuracy=0.927]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 24/100 [07:59<25:26, 20.09s/it, cross-entropy=0.259, accuracy=0.927]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 24/100 [07:59<25:26, 20.09s/it, cross-entropy=0.255, accuracy=0.928]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 25/100 [08:19<25:01, 20.02s/it, cross-entropy=0.255, accuracy=0.928]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 25/100 [08:19<25:01, 20.02s/it, cross-entropy=0.251, accuracy=0.93] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 26/100 [08:39<24:38, 19.97s/it, cross-entropy=0.251, accuracy=0.93]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██▌       | 26/100 [08:39<24:38, 19.97s/it, cross-entropy=0.247, accuracy=0.931]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 27/100 [08:59<24:15, 19.94s/it, cross-entropy=0.247, accuracy=0.931]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 27/100 [08:59<24:15, 19.94s/it, cross-entropy=0.243, accuracy=0.932]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 28/100 [09:19<23:58, 19.98s/it, cross-entropy=0.243, accuracy=0.932]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 28/100 [09:19<23:58, 19.98s/it, cross-entropy=0.24, accuracy=0.933] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▉       | 29/100 [09:39<23:40, 20.01s/it, cross-entropy=0.24, accuracy=0.933]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▉       | 29/100 [09:39<23:40, 20.01s/it, cross-entropy=0.236, accuracy=0.934]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 30/100 [09:59<23:18, 19.98s/it, cross-entropy=0.236, accuracy=0.934]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 30/100 [09:59<23:18, 19.98s/it, cross-entropy=0.233, accuracy=0.935]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 31/100 [10:19<22:59, 19.99s/it, cross-entropy=0.233, accuracy=0.935]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███       | 31/100 [10:19<22:59, 19.99s/it, cross-entropy=0.229, accuracy=0.936]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 32/100 [10:39<22:40, 20.00s/it, cross-entropy=0.229, accuracy=0.936]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|███▏      | 32/100 [10:39<22:40, 20.00s/it, cross-entropy=0.226, accuracy=0.937]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 33/100 [10:59<22:16, 19.95s/it, cross-entropy=0.226, accuracy=0.937]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 33/100 [10:59<22:16, 19.95s/it, cross-entropy=0.223, accuracy=0.938]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 34/100 [11:19<21:54, 19.91s/it, cross-entropy=0.223, accuracy=0.938]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|███▍      | 34/100 [11:19<21:54, 19.91s/it, cross-entropy=0.22, accuracy=0.939] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 35/100 [11:39<21:31, 19.88s/it, cross-entropy=0.22, accuracy=0.939]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███▌      | 35/100 [11:39<21:31, 19.88s/it, cross-entropy=0.217, accuracy=0.94]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 36/100 [11:58<21:10, 19.85s/it, cross-entropy=0.217, accuracy=0.94]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 36/100 [11:58<21:10, 19.85s/it, cross-entropy=0.214, accuracy=0.941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 37/100 [12:19<20:57, 19.96s/it, cross-entropy=0.214, accuracy=0.941]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 37/100 [12:19<20:57, 19.96s/it, cross-entropy=0.211, accuracy=0.942]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 38/100 [12:39<20:51, 20.19s/it, cross-entropy=0.211, accuracy=0.942]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 38/100 [12:39<20:51, 20.19s/it, cross-entropy=0.208, accuracy=0.942]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 39/100 [13:00<20:36, 20.27s/it, cross-entropy=0.208, accuracy=0.942]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███▉      | 39/100 [13:00<20:36, 20.27s/it, cross-entropy=0.206, accuracy=0.943]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 40/100 [13:20<20:12, 20.22s/it, cross-entropy=0.206, accuracy=0.943]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 40/100 [13:20<20:12, 20.22s/it, cross-entropy=0.203, accuracy=0.944]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 41/100 [13:40<19:54, 20.25s/it, cross-entropy=0.203, accuracy=0.944]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████      | 41/100 [13:40<19:54, 20.25s/it, cross-entropy=0.2, accuracy=0.944]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 42/100 [14:00<19:22, 20.05s/it, cross-entropy=0.2, accuracy=0.944]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████▏     | 42/100 [14:00<19:22, 20.05s/it, cross-entropy=0.198, accuracy=0.945]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [14:20<18:56, 19.94s/it, cross-entropy=0.198, accuracy=0.945]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 43/100 [14:20<18:56, 19.94s/it, cross-entropy=0.195, accuracy=0.946]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▍     | 44/100 [14:39<18:32, 19.86s/it, cross-entropy=0.195, accuracy=0.946]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████▍     | 44/100 [14:39<18:32, 19.86s/it, cross-entropy=0.193, accuracy=0.947]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 45/100 [14:59<18:08, 19.79s/it, cross-entropy=0.193, accuracy=0.947]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████▌     | 45/100 [14:59<18:08, 19.79s/it, cross-entropy=0.191, accuracy=0.947]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 46/100 [15:19<17:49, 19.81s/it, cross-entropy=0.191, accuracy=0.947]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|████▌     | 46/100 [15:19<17:49, 19.81s/it, cross-entropy=0.188, accuracy=0.948]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 47/100 [15:40<17:46, 20.12s/it, cross-entropy=0.188, accuracy=0.948]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 47/100 [15:40<17:46, 20.12s/it, cross-entropy=0.186, accuracy=0.949]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 48/100 [15:59<17:23, 20.08s/it, cross-entropy=0.186, accuracy=0.949]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████▊     | 48/100 [15:59<17:23, 20.08s/it, cross-entropy=0.184, accuracy=0.949]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 49/100 [16:19<17:00, 20.01s/it, cross-entropy=0.184, accuracy=0.949]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████▉     | 49/100 [16:19<17:00, 20.01s/it, cross-entropy=0.182, accuracy=0.95] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 50/100 [16:39<16:40, 20.00s/it, cross-entropy=0.182, accuracy=0.95]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 50/100 [16:39<16:40, 20.00s/it, cross-entropy=0.18, accuracy=0.95] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████     | 51/100 [17:00<16:22, 20.05s/it, cross-entropy=0.18, accuracy=0.95]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████     | 51/100 [17:00<16:22, 20.05s/it, cross-entropy=0.178, accuracy=0.95]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 52/100 [17:20<16:15, 20.31s/it, cross-entropy=0.178, accuracy=0.95]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████▏    | 52/100 [17:20<16:15, 20.31s/it, cross-entropy=0.176, accuracy=0.951]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 53/100 [17:41<15:52, 20.28s/it, cross-entropy=0.176, accuracy=0.951]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 53/100 [17:41<15:52, 20.28s/it, cross-entropy=0.174, accuracy=0.952]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 54/100 [18:01<15:31, 20.24s/it, cross-entropy=0.174, accuracy=0.952]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████▍    | 54/100 [18:01<15:31, 20.24s/it, cross-entropy=0.172, accuracy=0.952]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 55/100 [18:21<15:08, 20.18s/it, cross-entropy=0.172, accuracy=0.952]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████▌    | 55/100 [18:21<15:08, 20.18s/it, cross-entropy=0.17, accuracy=0.952] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 56/100 [18:41<14:44, 20.10s/it, cross-entropy=0.17, accuracy=0.952]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▌    | 56/100 [18:41<14:44, 20.10s/it, cross-entropy=0.168, accuracy=0.953]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 57/100 [19:01<14:28, 20.19s/it, cross-entropy=0.168, accuracy=0.953]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 57/100 [19:01<14:28, 20.19s/it, cross-entropy=0.166, accuracy=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 58/100 [19:22<14:14, 20.35s/it, cross-entropy=0.166, accuracy=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████▊    | 58/100 [19:22<14:14, 20.35s/it, cross-entropy=0.164, accuracy=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 59/100 [19:42<13:52, 20.31s/it, cross-entropy=0.164, accuracy=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 59/100 [19:42<13:52, 20.31s/it, cross-entropy=0.162, accuracy=0.955]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 60/100 [20:02<13:25, 20.15s/it, cross-entropy=0.162, accuracy=0.955]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 60/100 [20:02<13:25, 20.15s/it, cross-entropy=0.161, accuracy=0.956]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 61/100 [20:22<13:06, 20.16s/it, cross-entropy=0.161, accuracy=0.956]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|██████    | 61/100 [20:22<13:06, 20.16s/it, cross-entropy=0.159, accuracy=0.956]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 62/100 [20:42<12:46, 20.17s/it, cross-entropy=0.159, accuracy=0.956]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████▏   | 62/100 [20:42<12:46, 20.17s/it, cross-entropy=0.157, accuracy=0.957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 63/100 [21:02<12:26, 20.17s/it, cross-entropy=0.157, accuracy=0.957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 63/100 [21:02<12:26, 20.17s/it, cross-entropy=0.156, accuracy=0.957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 64/100 [21:22<11:59, 19.98s/it, cross-entropy=0.156, accuracy=0.957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|██████▍   | 64/100 [21:22<11:59, 19.98s/it, cross-entropy=0.154, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 65/100 [21:42<11:38, 19.96s/it, cross-entropy=0.154, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 65/100 [21:42<11:38, 19.96s/it, cross-entropy=0.152, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 66/100 [22:02<11:19, 19.99s/it, cross-entropy=0.152, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████▌   | 66/100 [22:02<11:19, 19.99s/it, cross-entropy=0.151, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 67/100 [22:23<11:05, 20.18s/it, cross-entropy=0.151, accuracy=0.958]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 67/100 [22:23<11:05, 20.18s/it, cross-entropy=0.149, accuracy=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 68/100 [22:42<10:41, 20.05s/it, cross-entropy=0.149, accuracy=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████▊   | 68/100 [22:42<10:41, 20.05s/it, cross-entropy=0.148, accuracy=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 69/100 [23:03<10:24, 20.16s/it, cross-entropy=0.148, accuracy=0.959]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████▉   | 69/100 [23:03<10:24, 20.16s/it, cross-entropy=0.146, accuracy=0.96] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 70/100 [23:23<10:02, 20.09s/it, cross-entropy=0.146, accuracy=0.96]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 70/100 [23:23<10:02, 20.09s/it, cross-entropy=0.145, accuracy=0.96]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████   | 71/100 [23:43<09:42, 20.07s/it, cross-entropy=0.145, accuracy=0.96]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████   | 71/100 [23:43<09:42, 20.07s/it, cross-entropy=0.144, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 72/100 [24:03<09:21, 20.07s/it, cross-entropy=0.144, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████▏  | 72/100 [24:03<09:21, 20.07s/it, cross-entropy=0.142, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 73/100 [24:23<09:02, 20.09s/it, cross-entropy=0.142, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 73/100 [24:23<09:02, 20.09s/it, cross-entropy=0.141, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 74/100 [24:43<08:40, 20.04s/it, cross-entropy=0.141, accuracy=0.961]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████▍  | 74/100 [24:43<08:40, 20.04s/it, cross-entropy=0.14, accuracy=0.962] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 75/100 [25:03<08:21, 20.04s/it, cross-entropy=0.14, accuracy=0.962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 75/100 [25:03<08:21, 20.04s/it, cross-entropy=0.138, accuracy=0.962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 76/100 [25:23<08:01, 20.04s/it, cross-entropy=0.138, accuracy=0.962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████▌  | 76/100 [25:23<08:01, 20.04s/it, cross-entropy=0.137, accuracy=0.962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 77/100 [25:43<07:42, 20.10s/it, cross-entropy=0.137, accuracy=0.962]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 77/100 [25:43<07:42, 20.10s/it, cross-entropy=0.136, accuracy=0.963]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 78/100 [26:03<07:22, 20.11s/it, cross-entropy=0.136, accuracy=0.963]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|███████▊  | 78/100 [26:03<07:22, 20.11s/it, cross-entropy=0.134, accuracy=0.963]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▉  | 79/100 [26:23<07:01, 20.05s/it, cross-entropy=0.134, accuracy=0.963]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|███████▉  | 79/100 [26:23<07:01, 20.05s/it, cross-entropy=0.133, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 80/100 [26:43<06:40, 20.04s/it, cross-entropy=0.133, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 80/100 [26:43<06:40, 20.04s/it, cross-entropy=0.132, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 81/100 [27:03<06:20, 20.02s/it, cross-entropy=0.132, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|████████  | 81/100 [27:03<06:20, 20.02s/it, cross-entropy=0.131, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 82/100 [27:23<06:02, 20.11s/it, cross-entropy=0.131, accuracy=0.964]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████▏ | 82/100 [27:23<06:02, 20.11s/it, cross-entropy=0.13, accuracy=0.965] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 83/100 [27:44<05:41, 20.10s/it, cross-entropy=0.13, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 83/100 [27:44<05:41, 20.10s/it, cross-entropy=0.128, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 84/100 [28:04<05:22, 20.16s/it, cross-entropy=0.128, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████▍ | 84/100 [28:04<05:22, 20.16s/it, cross-entropy=0.127, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [28:24<05:00, 20.05s/it, cross-entropy=0.127, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████▌ | 85/100 [28:24<05:00, 20.05s/it, cross-entropy=0.126, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 86/100 [28:44<04:43, 20.25s/it, cross-entropy=0.126, accuracy=0.965]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 86/100 [28:44<04:43, 20.25s/it, cross-entropy=0.125, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 87/100 [29:05<04:23, 20.29s/it, cross-entropy=0.125, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 87/100 [29:05<04:23, 20.29s/it, cross-entropy=0.124, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 88/100 [29:25<04:03, 20.26s/it, cross-entropy=0.124, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████▊ | 88/100 [29:25<04:03, 20.26s/it, cross-entropy=0.123, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 89/100 [29:45<03:42, 20.21s/it, cross-entropy=0.123, accuracy=0.966]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|████████▉ | 89/100 [29:45<03:42, 20.21s/it, cross-entropy=0.122, accuracy=0.967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 90/100 [30:05<03:21, 20.16s/it, cross-entropy=0.122, accuracy=0.967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 90/100 [30:05<03:21, 20.16s/it, cross-entropy=0.121, accuracy=0.967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 91/100 [30:25<03:01, 20.13s/it, cross-entropy=0.121, accuracy=0.967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|█████████ | 91/100 [30:25<03:01, 20.13s/it, cross-entropy=0.12, accuracy=0.967] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 92/100 [30:45<02:41, 20.13s/it, cross-entropy=0.12, accuracy=0.967]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|█████████▏| 92/100 [30:45<02:41, 20.13s/it, cross-entropy=0.119, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 93/100 [31:05<02:20, 20.14s/it, cross-entropy=0.119, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 93/100 [31:05<02:20, 20.14s/it, cross-entropy=0.118, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 94/100 [31:26<02:02, 20.36s/it, cross-entropy=0.118, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|█████████▍| 94/100 [31:26<02:02, 20.36s/it, cross-entropy=0.117, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 95/100 [31:47<01:42, 20.46s/it, cross-entropy=0.117, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|█████████▌| 95/100 [31:47<01:42, 20.46s/it, cross-entropy=0.116, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 96/100 [32:08<01:22, 20.57s/it, cross-entropy=0.116, accuracy=0.968]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|█████████▌| 96/100 [32:08<01:22, 20.57s/it, cross-entropy=0.115, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 97/100 [32:28<01:01, 20.58s/it, cross-entropy=0.115, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 97/100 [32:28<01:01, 20.58s/it, cross-entropy=0.114, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 98/100 [32:48<00:40, 20.33s/it, cross-entropy=0.114, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████▊| 98/100 [32:48<00:40, 20.33s/it, cross-entropy=0.113, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████▉| 99/100 [33:08<00:20, 20.25s/it, cross-entropy=0.113, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████▉| 99/100 [33:08<00:20, 20.25s/it, cross-entropy=0.112, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 100/100 [33:28<00:00, 20.24s/it, cross-entropy=0.112, accuracy=0.969]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 100/100 [33:28<00:00, 20.24s/it, cross-entropy=0.112, accuracy=0.97] \u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "loss_history_train, accuracy_history_train, \\\n",
    "loss_history_eval, accuracy_history_eval = train_loop(DATASET, model, loss, epochs=100, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим на одном графике значение лосса и метрики для тренировочной и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5));\n",
    "\n",
    "ax[0].plot(loss_history_train, label='train')\n",
    "ax[0].plot(loss_history_eval, label='test')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Cross-Entropy loss')\n",
    "ax[0].set_title('Cross-entropy loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(accuracy_history_train, label='train')\n",
    "ax[1].plot(accuracy_history_eval, label='test')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy score')\n",
    "ax[1].set_title('Accuracy metrics')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что переобучения не наблюдается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества\n",
    "Наконец, воспользуясь обученном моделью, сделаем `predict` на данных, которые она никогда не видела (здесь можно придумать интерпретацию, что это данные уже непосредственно увиденные моделью на продакшне)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальный accuracy на test: 0.9596\n"
     ]
    }
   ],
   "source": [
    "# переходим в режим оценивания без кэширования\n",
    "model.evaluate_mode()\n",
    "\n",
    "correct = 0\n",
    "y_pred = []\n",
    "for X_batch, y_batch in generate_batches(X_test.values, y_test_one_hot, batch_size=128):\n",
    "    y_batch_pred = model(X_batch)\n",
    "    y_pred_one_hot = make_one_hot(np.argmax(y_batch_pred, axis=1))\n",
    "    y_pred.extend(y_pred_one_hot)\n",
    "    \n",
    "    correct += (y_pred_one_hot == y_batch).all(axis=1).sum()\n",
    "\n",
    "print(f\"Финальный accuracy на test: {correct / len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе была реализована модель, задача которой научиться классфицировать датасет `MNIST`. В плане оптимизации вычислений, использовался `back propagation`, а также `SGD+Momentum`.\n",
    "\n",
    "Как итог, видно, что модель со своей задачей справилась, ведь об этом свидетельствует значение метрики. Переобучения не было, но это скорее связано с тем, что модель вообще неглубокая, потому что ни каких явных попыток регуляризации я не предприминмал по ходу обучения.\n",
    "\n",
    "Также я почти уверен, что данные избыточны, поскольку помимо константных пискелей (которые я благополучно удалил на этапе предобработки), есть также и те, тональность которых совсем чуть-чуть менялась. Наверное, в таком случае было бы хорошо использовать более продвинутые методы, вроде `PCA`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
