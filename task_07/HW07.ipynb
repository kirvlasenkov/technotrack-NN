{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN в задаче идентификации аномалий в геофизических данных\n",
    "<br /><br />\n",
    "В этом исследовании предлагается применить WGAN для идентификации аномалий в данных, описывающих состояние стратосферы на уровне 10гПа в северном полушарии.\n",
    "<br /><br />\n",
    "Известно, что обычно состояние стратосферы над северным полушарием в зимний период описывается как стратосферный полярный вихрь (СПВ). Это вихрь, образующийся под действием силы Кориолиса при условии выхолаживания полярной области стратосферы и, как следствие, возникновения градиента давления между полярной областью и умеренными широтами.\n",
    "\n",
    "### Исходные данные\n",
    "В этом исследовании состояние стратосферы будет описываться полями потенциальной завихренности (переменная `pv`) и высоты геопотенциала (переменная `gh`) на уровне 10гПа. Эти данные ограничены по широте: в исходных файлах представлены значения севернее $40^\\circ$N, спроецированные с использованием полярной проекции. Кроме того, исходные данные уже отнормированы к интервалу $[0,1]$. Примеры полученного таким образом признакового описания состояний стратосферы приведены на рисунке ниже.\n",
    "<br /><br />\n",
    "Исходные данные исследования можно скачать по следующим ссылкам: [pv data](https://www.dropbox.com/s/ohwfyrmj4zl94q9/pv_data_projected_all.normed01.npy?dl=0); [gh data](https://www.dropbox.com/s/v3qjgzsls6et6cw/hgt_data_projected_all.normed01.npy?dl=0)\n",
    "<br />\n",
    "Маску для исключения несущественных зон снимка из рассмотрения можно скачать по ссылке: [mask data](https://www.dropbox.com/s/7s6lgdi01f8plkz/mask_256.npy?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/source_data_example.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Внезапные стратосферные потепления как аномалии\n",
    "Примерно с частотой один раз в 1.6 лет состояние стратосферы кардинально меняется, и сильный устойчивый вихрь, видный на диаграмме выше, распадается совсем или как минимум сильно возмущается и смещается с полюса. Эти состояния редки, и именно поэтому в этом исследовании будем считать их аномалиями. Цель исследования - применить набор нейросетевых моделей для поиска таких аномалий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Порождающие состязательные сети\n",
    "Порождающие состязательные сети (ПСС, Generative Adversarial Networks, GAN) - нейросетевые модели, отличающиеся от обычных дискриминативных моделей в смысле методики обучения и сэмплирования данных.\n",
    "\n",
    "<center><img src=\"img/GAN_en.png\" width=600></center>\n",
    "\n",
    "Терминология в GAN включает \"реальные объекты\" (real objects) - такие, которые порождены реальным процессом и даны в форме обучающей выборки, и \"фейковые\" или \"порожденные\" объекты (fake objects) - такие, которые являются результатом вычисления генератора $\\mathcal{G}(\\mathbb{\\cdot})$ на входных данных $z$. При этом входные данные $z$ - это шум, порожденный из специального распределения. Обычно берут многомерное стандартное нормальное распределение. Порождаемые векторы шума (noise) также называют векторами скрытого представления (hidden representations или embeddings) по аналогии с терминологией автокодировщиков. В этом смысле генератор GAN - аналог декодера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом дискриминатор $\\mathcal{D}(\\mathbb{\\cdot})$ - подсеть, задача которой различать реальные и фейковые объекты, базируясь на их признаковом представлении. В определенном смысле дискриминатор - всего лишь нейросеть, решающая задачу бинарной классификации между реальными и фейковыми объектами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип обучения GAN состоит в том, что две подсети (генератор и дискриминатор) должны решать две противоположные задачи: генератор должен порождать примеры, настолько похожие на реальные, чтобы дискриминатор не мог их различить; при этом дискриминатор должен учиться все равно различать эти примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначения, которые вводятся для GAN:\n",
    "- $z$ - шумовой вектор (noise) в пространстве скрытых представлений $\\mathbb{Z}$;\n",
    "- $x$ - признаковое описание реального объекта (!!! именно в пространстве признаков $\\mathbb{X}$ !!!);\n",
    "- $\\mathcal{G}(z)$ - генератор, нейросеть, порождающая \"фейковые\" объекты из векторов $z$. Генератор переводит векторы пространства $\\mathbb{Z}$ в векторы пространства $\\mathbb{X}$:\n",
    "$$\n",
    "\\mathcal{G}(\\mathbf{\\cdot}): \\mathbb{Z}\\to\\mathbb{X}\n",
    "$$\n",
    "- $\\mathcal{D}(x)$ - дискриминатор, нейросеть, решающая задачу классификации векторов пространства $\\mathbb{X}$ на \"реальные\" и \"фейковые\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Псевдоалгоритм обучения GAN:\n",
    "<br /><br />\n",
    "<center><img src=\"img/gan_algo.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный алгоритм обучения GAN оказался нестабильным, и для его стабилизации были предложены усовершенствования, получившие название Wasserstein GAN ([WGAN](https://arxiv.org/abs/1701.07875)).\n",
    "<br />\n",
    "обозначения, принятые в этой статье:\n",
    "- $g(z)$ - генератор;\n",
    "- $f(x)$ - дискриминатор.\n",
    "<br /><br />\n",
    "Псевдоалгоритм обучения WGAN:\n",
    "<br /><br />\n",
    "<center><img src=\"img/wgan_algo.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем был предложен усовершенствованный алгоритм обучения WGAN с наложением ограничений на градиент дискриминатора $\\mathcal{D}(x)$ по входным данным $x$ - Wasserstein GAN with Gradient Penalty ([WGAN-GP](https://arxiv.org/abs/1704.00028))\n",
    "<br /><br />\n",
    "Псевдоалгоритм обучения WGAN-GP:\n",
    "<center><img src=\"img/wgan-gp-algo.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании предлагается обратить внимание на свойство GAN аппроксимировать распределение данных. Это можно интуитивно понять на примере следующей пары диаграмм:\n",
    "<center><img src=\"img/WGAN-mapping.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь на левой панели условно отображены векторы скрытых представлений $z$ в пространстве скрытых представлений $\\mathbb{Z}$. Напомним, что эти векторы порождаются из стандартного нормального распределения. На правой панели диаграммы условно отображаются объекты $x$ в пространстве признакового описания объектов $\\mathbb{X}$. Здаесь они отображены в двумерном пространстве, однако нужно помнить, что в предлагаемой задаче это векторы в пространстве размерности `2*256*256`, поскольку признаковое описание состояний стратосферы составлено двумя полями (`pv` и `gh`), каждое из которых представляет собой матрицу размером `256x256`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На диаграмме условно отображено соответствие областей в пространствах $\\mathbb{Z}$ и $\\mathbb{X}$, в которых сосредоточена основная часть объектов выборки (точки оранжевого цвета). Точками синего цвета условно отображены объекты, являющиеся выбросами (аномалиями) для данных выборки. С точки зрения распределения переменной $z$ эти объекты лежат за пределами основной массы распределения, то есть, могут быть интерпретированы, например, как векторы, норма которых больше перцентиля уровня $98\\%$. В это же время, в пространстве признакового описания $\\mathbb{X}$ соответствующие объекты, вычисляемые как $\\mathcal{G}(z)$ могут считаться аномалиями (синие точки на правой панели диаграммы)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения задачи идентификации аномалий в этом случае остается только один вопрос: **как в пространстве $\\mathbb{X}$ построить разделяющую поверхность**, соответствующую разделяющей поверхности, проходящей по перцентилю $98\\%$ нормы векторов $z$ в пространстве $\\mathbb{Z}$. Это при условии, что **вряд ли найдется возможность обратить преобразование генератора и получить $\\mathcal{G}^{-1}(x)$**. А именно такое преобразование понадобилось бы для того, чтобы протестировать вновь поступающие на анализ события $x\\in\\mathbb{X}$ на принадлежность области \"обычных\" или \"аномальных\" объектов в пространстве $\\mathbb{Z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение WGAN-GP для порождения сбалансированной выборки \"обычных\" и \"аномальных\" объектов\n",
    "\n",
    "В качестве альтернативного решения такой задачи в этом задании (во второй части) предлагается создать нейросетевой классификатор $\\mathcal{F}(x)$, способный разделять объекты $x$ на обычные, характерные для выборки, и аномальные. Вопрос в том, - как его обучить?\n",
    "\n",
    "В случае, когда в нашем распоряжении есть генератор $\\mathcal{G}(z)$, обученный порождать как \"обычные\" объекты, так и \"аномальные\", можно сгенерировать достаточное количество обучающих примеров для такого бинарного классификатора $\\mathcal{F}(x)$. При этом метка $y_i$ \"обычный\"/\"аномальный\" будет доступна по условию порождения таких примеров: в силах исследователя в момент генерации шумового вектора $z_i$ классифицировать его, руководствуясь его нормой:\n",
    "\n",
    "- Если $|z_i|_2>q_{0.98}(|z|_2)$, то объект может считаться аномальным, $y_i=1$\n",
    "- Иначе объект может считаться обычным, $y_i=0$\n",
    "\n",
    "Отметим также, что в силах исследователя регулировать порождение сбалансированной выборки, что важно для обучения надежного классификатора. Для этого на этапе порождения векторов $z$ следует следить за сбалансированностью их с точки зрения классификации на \"обычные\" и \"аномальные\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c971a5eb8f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__version__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.15'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TensorBoard logging requires TensorBoard version 1.15 or above'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from libs.service_defs import *\n",
    "import torch.autograd as autograd\n",
    "from scipy import stats\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим доступность GPU\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self,\n",
    "                 pv_fname: str = ''\n",
    "                 gh_fname: str = '',\n",
    "                 mask_fname: str = '',\n",
    "                 transform: Any = None):\n",
    "        \n",
    "        '''\n",
    "        здесь должен быть код инициализациия экземпляра класса DS\n",
    "        В нем следует считать данные и записать в виде атрибутов этого экземпляра класса\n",
    "        Также следует сохранить в качестве атрибута этого экземпляра класса преобразование(я) transform,\n",
    "            которые должны будут применяться к данным\n",
    "        \n",
    "        '''\n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "        self.pv_name = pv_name\n",
    "        self.gh_name = gh_name\n",
    "        self.mask_fname = mask_fname\n",
    "        self.transform = transrform\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = np.zeros((1,2,256,256))\n",
    "        '''\n",
    "        Здесь должно быть описание процедуры составления (возможно, из заранее прочитанных данных)\n",
    "            признакового описания запрашиваемого по индексу index объекта,\n",
    "            а также применения преобразований transform, если они есть.\n",
    "        Этот метод должен выдавать признаковое описание объекта.\n",
    "        Подсказка: размерность признакового описания одного объекта должна быть [1,2,256,256], где\n",
    "        1 - нумерует (единственный) объект в этой выборке\n",
    "        2 - нумерует \"каналы\" данных (pv и gh)\n",
    "        256,256 - индексирует пространственные переменные\n",
    "        '''\n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        '''\n",
    "        Этот метод должен возвращать полное количество объектов в выборке\n",
    "        '''\n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = lambda x: Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DS('/path/to/pv_data_projected_all.normed01.npy',\n",
    "                   '/path/to/gh_data_projected_all.normed01.npy',\n",
    "                   '/path/to/mask_256.npy',\n",
    "                   train_transforms)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для контроля можно отобразить порождаемые этим классом объекты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(train_dataset), size=8)\n",
    "samples = [train_dataset[idx] for idx in indices]\n",
    "\n",
    "fig = plt.figure(figsize=(2, 8), dpi=300)\n",
    "for idx,sample in enumerate(samples):\n",
    "    sample_np = sample.numpy()\n",
    "    p = plt.subplot(8,2,idx*2+1)\n",
    "    plt.imshow(sample_np[0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    p = plt.subplot(8,2,idx*2+2)\n",
    "    plt.imshow(sample_np[1], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее следует описать подсети генератора $\\mathcal{G}(\\cdot)$ и дискриминатора $\\mathcal{D}(\\cdot)$\n",
    "\n",
    "Напомним, генератор принимает на вход вектор размерности `n_inputs` (в случае мини-батча размером `N` - матрицу `N x n_inputs`) и возвращает тензор размером `N x 2 x 256 x 256`\n",
    "\n",
    "При этом дискриминатор принимает на вход тензоры размером `N x 2 x 256 x 256` и действует как бинарный классификатор: выходное значение - одно действительное число на каждый объект. То есть, размерность выходного тензора должна быть `N x 1`. В случае WGAN-GP это выходное значение не ограничивается по величине и может принимать все действительные значения (подумайте, какая в этом случае должна быть функция активации выходного слоя)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs=128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "\n",
    "    def forward(self, x_noise):\n",
    "        x = x_noise\n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее применим описанные классы генератора и дискриминатора для создания WGAN-GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(n_inputs=latent_dim)\n",
    "gen = gen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = Discriminator()\n",
    "dsc = dsc.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также следует создать оптимизаторы отдельно для генератора и для дискриминатора\n",
    "opt_gen = None # YOUR CODE HERE\n",
    "opt_dsc = None # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели WGAN-GP применяется регуляризация на градиент выхода дискриминатора по его входным данным. Здесь предлагается воспользовать его реализацией, приведенной ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(model_dsc, real_samples, fake_samples):\n",
    "    \"\"\"\n",
    "    Calculates the gradient penalty loss for WGAN GP\n",
    "    model_dsc - дискриминатор\n",
    "    real_samples - признаковое описание реальных примеров\n",
    "    fake_samples - признаковое описание примеров, порожденных генератором.\n",
    "    \"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = model_dsc(interpolates)\n",
    "    fake = Variable(Tensor(d_interpolates.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(outputs=d_interpolates,\n",
    "                              inputs=interpolates,\n",
    "                              grad_outputs=fake,\n",
    "                              create_graph=True,\n",
    "                              retain_graph=True,\n",
    "                              only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_gen: torch.nn.Module, \n",
    "                model_dsc: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                optimizer_gen: torch.optim.Optimizer,\n",
    "                optimizer_dsc: torch.optim.Optimizer,\n",
    "                batch_size = 32,\n",
    "                max_epochs = 10,\n",
    "                n_critic = 5,\n",
    "                lambda_gp = 10):\n",
    "    \n",
    "    '''\n",
    "    В этой функции следует запрограммировать обучение и валидацию WGAN-GP.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    train_loader = None # YOUR CODE HERE\n",
    "    \n",
    "    lr_scheduler_gen = None # YOUR CODE HERE\n",
    "    lr_scheduler_dsc = None # YOUR CODE HERE\n",
    "        \n",
    "    # Полезно будет записать эволюцию функций потерь по ходу обучения - ее можно будет потом отобразить на диаграмме\n",
    "    val_loss_history = []\n",
    "    gen_loss_history = []\n",
    "    dsc_loss_history = []\n",
    "    lgen = 0.0\n",
    "    ldsc = 0.0\n",
    "    \n",
    "    # Далее следует написать цикл оптимизации генератора и дискриминатора,\n",
    "    # руководствуясь псевдоалгоритмом, приведенным в описании выше\n",
    "    # Замечание: Не забудьте применить маску как к реальным данным (это можно сделать в генераторе данных DS),\n",
    "    #           так и к данным, порождаемым генератором!\n",
    "    \n",
    "       \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print(f'Starting epoch {epoch+1} of {max_epochs}')\n",
    "        \n",
    "        model_gen.train()\n",
    "        model_dsc.train()\n",
    "        \n",
    "        with tqdm(total=len(train_loader)) as pbar:\n",
    "            for idx, real_batch in enumerate(train_loader):\n",
    "                \n",
    "                ################################\n",
    "                ###    YOUR CODE HERE        ###\n",
    "                ################################\n",
    "                # шаг оптимизации дискриминатора\n",
    "\n",
    "                if idx % n_critic == 0:\n",
    "                    \n",
    "                    ################################\n",
    "                    ###    YOUR CODE HERE        ###\n",
    "                    ################################\n",
    "                    # шаг оптимизации генератора\n",
    "                \n",
    "                pbar.update(1)\n",
    "                \n",
    "                pbar.set_postfix({'step': idx+1, 'loss_GEN': lgen, 'loss_DSC': ldsc})\n",
    "                \n",
    "        # Тут рекомендуется сохранять модели каждую эпоху\n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "        \n",
    "        # Валидация - оценка функции потерь WGAN-GP (без регуляризационного члена) как D(x_real) - D(x_fake)\n",
    "        \n",
    "        model_gen.eval()\n",
    "        model_dsc.eval()\n",
    "        val_loss_epoch = 0.0\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "        \n",
    "        val_loss_history.append(val_loss_epoch)\n",
    "        \n",
    "        lr_scheduler_gen.step()\n",
    "        lr_scheduler_dsc.step()\n",
    "        \n",
    "    return val_loss_history, dsc_loss_history, gen_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, dsc_loss_history, gen_loss_history = train_model(gen, dsc,\n",
    "                                                               train_dataset,\n",
    "                                                               opt_gen, opt_dsc,\n",
    "                                                               max_epochs=300,\n",
    "                                                               n_critic=4,\n",
    "                                                               lambda_gp=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества обучения, полезно посмотреть на кривые обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8,3), dpi=300)\n",
    "p = plt.subplot(1,3,1)\n",
    "_ = plt.scatter(np.arange(len(loss_history)), loss_history, s=1)\n",
    "\n",
    "p = plt.subplot(1,3,2)\n",
    "_ = plt.scatter(np.arange(len(dsc_loss_history)), dsc_loss_history, s=1)\n",
    "\n",
    "p = plt.subplot(1,3,3)\n",
    "_ = plt.scatter(np.arange(len(gen_loss_history)), gen_loss_history, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее предлагается применить генератор для порождения новых примеров и оценить их правдоподобность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, real_batch in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При необходимости можно загрузить нужное состояние генератора\n",
    "gen = Generator(n_inputs=latent_dim)\n",
    "gen.load_state_dict(torch.load('./path/to/model/checkpoint/gen.pt'))\n",
    "gen = gen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = real_batch.to(DEVICE)\n",
    "noise = Variable(torch.tensor(np.random.normal(0, 1, (len(real_batch), latent_dim)),\n",
    "                              dtype=torch.float, device=DEVICE))\n",
    "fake_batch = gen(noise)\n",
    "\n",
    "# Замечание: Не забудьте применить маску к данным, порождаемым генератором!\n",
    "################################\n",
    "###    YOUR CODE HERE        ###\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = real_batch.detach().cpu().numpy()\n",
    "fake_batch = fake_batch.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(4,4), dpi=300)\n",
    "p = plt.subplot(2,2,1)\n",
    "plt.imshow(real_batch[0,0,...], cmap='gray')\n",
    "plt.axis('off')\n",
    "p = plt.subplot(2,2,2)\n",
    "plt.imshow(real_batch[0,1,...], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "p = plt.subplot(2,2,3)\n",
    "plt.imshow(fake_batch[2,0,...], cmap='gray')\n",
    "plt.axis('off')\n",
    "p = plt.subplot(2,2,4)\n",
    "plt.imshow(fake_batch[2,1,...], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(np.arange(32), 16, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(4,4), dpi=300)\n",
    "\n",
    "for i,idx in enumerate(indices):\n",
    "    p = plt.subplot(4,4,i+1)\n",
    "    plt.imshow(fake_batch[idx,0,...], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(4,4), dpi=300)\n",
    "\n",
    "for i,idx in enumerate(indices):\n",
    "    p = plt.subplot(4,4,i+1)\n",
    "    plt.imshow(fake_batch[idx,1,...], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование обученного генератора $\\mathcal{G}(\\mathbb{\\cdot})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части задания предлагается использовать генератор, обученный в первой части, для порождения примеров, похожих на представленные в обучающей выборке. Напомним, что векторы $z$ порождаются многомерным стандартным нормальным распределением, однако в этом задании следует изменить соотношение обычных экземпляров и экземпляров-аномалий. Этого можно добиться двумя способами:\n",
    "\n",
    "- Сэмплировать с отклонением (отвержением) примеров. В этом случае векторы $z$ порождаются из стандартного нормального распределения, однако при этом экземпляры с нормой менее перцентиля уровня $98\\%$ отклоняются с вероятностью, близкой к $98\\%$ (вычислите, какова в точности должна быть вероятность отвержения, если Вы выбрали этот способ сэмплирования). Этот способ гарантирует получение сбалансированной выборки \"обычных\" и \"аномальных\" векторов $z$, однако не гарантирует равномерного сэмплирования внутри области \"обычных\" примеров;\n",
    "- Сэмплировать равномерно в некоторой области, ограниченной нормой $z$: $z\\leq z_{max}$. Здесь тоже должно быть задействовано сэмплирование с отвержением, однако условие отвержения будет другим. Если это ваш выбор, вычислите, каково должно быть $z_{max}$, чтобы выборка обычных и аномальных примеров была сбалансирована. Напомним: известно, что разделение обычных и аномальных примеров в пространстве $\\mathbb{Z}$ проходит по значению нормы вектора $|z|_2=q_{0.98}(|z|_2)$. Обратите внимание, что эта величина зависит от размерности $n$ случайной величины $z$, поэтому правильнее писать $q_{0.98}(|z|_2, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка**: поскольку $z$ распределена нормально с единичной матрицей ковариаций $\\Sigma$, то каждая из компонент этого вектора распределена нормально с дисперсией $\\sigma^2=1$; это означает, что $(|z|_2)^2=\\sum_{j=1}^{n}z_j^2$ имеет распределение хи-квадрат, а $|z|_2=\\sqrt{\\sum_{j=1}^{n}z_j^2}$, соответственно, имеет распределение хи. Для вычисления величины $q_{0.98}(|z|_2, n)$ можно воспользоваться методами распределения, реализованными в библиотеке `scipy`: [`scipy.stats.chi`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы знаем, в пределах каких значений $|z|_2$ лежат векторы $z$, отображающиеся в \"обычные примеры\", нужно научиться сэмплировать их равномерно. Для реализации равномерного сэмплирования в $n$-шаре можно воспользоваться функцией равномерного сэмплирования в многомерном $n$-кубе [numpy.random.rand](https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html#numpy.random.rand) с отвержением экземпляров по норме $|z|_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого следует научиться сэмплировать векторы за пределами этого $n$-шара радиусом $q_{0.98}(|z|_2, n)$. Например, можно сэмплировать равномерно из шара радиусом $R_{outer}=2^{1/n}$ с отвержением всех экземпляров внутри вложенного шара, содержащего \"обычные\" примеры.\n",
    "\n",
    "**Подсказка**: можно сразу сэмплировать из шара радиусом $R_{outer}=q_{0.98}(|z|_2, n)*2^{1/n}$ и делить примеры на две категории: обычные (для которых $|z|_2\\leq q_{0.98}(|z|_2, n)$) и аномальные (все остальные экземпляры)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Об эффективном сэмплировании из $n$-мерного шара радиусом $R$\n",
    "\n",
    "В тот момент, когда требуется порождать векторы, равномерно распределенные в $n$-мерном шаре радиуса $R$, в первую очередь на ум приходит равномерное сэмплирование из $n$-мерного куба со стороной $2R$ с отклонением примеров за пределами шара. Однако с возрастанием количества измерений **$n$** эффективность (скорость) алгоритма такого равномерного сэмплирования резко падает. Вместо этого лучше воспользоваться другим способом:\n",
    "\n",
    "#### Псевдоалгоритм 1 - равномерного сэмплирования из $n$-мерного шара радиусом $R$\n",
    "1. Породить $\\mathbf{s}\\in \\mathbb{R}^n$ равномерно на поверхности $n-1$-мерной единичной сферы.\n",
    "2. Породить $c\\sim U[0,1]$ (из равномерного распределения с поддержкой $[0,1]$)\n",
    "3. Вернуть вектор $\\mathbf{b}=s*c^{1/n}*R$\n",
    "\n",
    "При этом нужно еще уметь равномерно порождать векторы $\\mathbf{s}\\in \\mathbb{R}^n$ на поверхности $n-1$-мерной единичной сферы. Для этого можно воспользоваться следующим алгоритмом:\n",
    "\n",
    "#### Псевдоалгоритм 2 - равномерного сэмплирования из $n-1$-мерной единичной сферы\n",
    "1. Породить $n$-мерный вектор, распределенный нормально с диагональной единичной матрицей ковариаций и нулевым вектором средних: $\\mathbf{d}\\sim\\mathcal{N}(\\mathbf{0}, \\mathbb{I})$.\n",
    "2. Вычислить $L_2$-норму вектора $\\mathbf{d}$:\n",
    "$$\n",
    "|\\mathbf{d}|_2=\\sqrt{\\sum_{i=1}^{n}d_i^2}\n",
    "$$\n",
    "3. Вернуть вектор-направление единичной длины $\\tilde{\\mathbf{d}}=\\frac{\\mathbf{d}}{|\\mathbf{d}|_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SamplingUnitSphereUniform(ndim=2, nsamples=100):\n",
    "    '''\n",
    "    Эта функция должна порождать примеры, равномерно распределенные по единичной n-мерной сфере\n",
    "        (см. псевдоалгоритм 2)\n",
    "    '''\n",
    "    ################################\n",
    "    ###    YOUR CODE HERE        ###\n",
    "    ################################\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SamplingBallUniform(ndim=2, radius=1, nsamples=100):\n",
    "    '''\n",
    "    Эта функция должна порождать примеры, равномерно распределенные в единичном n-мерном шаре\n",
    "        (см. псевдоалгоритм 1)\n",
    "    '''\n",
    "    ################################\n",
    "    ###    YOUR CODE HERE        ###\n",
    "    ################################\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampleInnerAndOuterExamples(ndim=2, radius_inner=1, radius_outer=2, nsamples=100):\n",
    "    '''\n",
    "    В этой функции следует порождать примеры, равномерно распределенные в ndim-мерном шаре диаметром radius_outer\n",
    "        и делить их на samples_inner (\"обычные\") и samples_outer (\"аномальные\")\n",
    "        по норме векторов с пороговым значением radius_inner\n",
    "    '''\n",
    "    ################################\n",
    "    ###    YOUR CODE HERE        ###\n",
    "    ################################\n",
    "    return samples_inner, samples_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверьте свою реализацию сэмплирования\n",
    "\n",
    "В качестве проверки можно породить, скажем, 10000 примеров, равномерно распределенных в двумерном шаре (на круге, $n=2$). Внешний радиус нужно поставить в значение $R_{outer}=q_{0.98}(|z|_2, n)*2^{1/n}$, внутренний - в значение $R_{inner}=q_{0.98}(|z|_2, n)$\n",
    "\n",
    "Ожидаемый результат:\n",
    "- примеров `examples_inner` и `examples_outer` должно получиться примерно одинаковое количество;\n",
    "- примеры распределены равномерно по кругу радиусом примерно 4;\n",
    "- \"обычные\" (внутри круга радиусом $R_{inner}$) и \"аномальные\" (в кольце между окружностями радиусом $R_{inner}$ и $R_{outer}$) примеры визуально не перемешиваются;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_inner, examples_outer = SampleInnerAndOuterExamples(ndim=2,\n",
    "                                                             radius_inner=stats.chi.ppf(0.98, 2),\n",
    "                                                             radius_outer=stats.chi.ppf(0.98, 2)*np.sqrt(2),\n",
    "                                                             nsamples=10000)\n",
    "examples_inner.shape[0], examples_outer.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(4,4), dpi=300)\n",
    "plt.scatter(examples_inner[:,0], examples_inner[:,1], s=1, color='orange')\n",
    "plt.scatter(examples_outer[:,0], examples_outer[:,1], s=1, color='blue')\n",
    "_ = plt.axis('equal')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Еще раз проверьте свою реализацию сэмплирования\n",
    "\n",
    "В качестве второй проверки можно породить, скажем, 10000 примеров, равномерно распределенных в шаре высокой размерности (например, $n=128$). Внешний радиус нужно поставить в значение $R_{outer}=q_{0.98}(|z|_2, n)*2^{1/n}$, внутренний - в значение $R_{inner}=q_{0.98}(|z|_2, n)$\n",
    "\n",
    "Ожидаемый результат:\n",
    "- примеров `examples_inner` и `examples_outer` должно получиться примерно одинаковое количество;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_p98 = 0.0 # YOUR CODE HERE - значение перцентиля уровня 98% распределения хи с количеством степеней свободы latent_dim\n",
    "print(chi_p98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_inner, examples_outer = SampleInnerAndOuterExamples(ndim=latent_dim,\n",
    "                                                             radius_inner=chi_p98,\n",
    "                                                             radius_outer=chi_p98*np.power(2, 1/latent_dim),\n",
    "                                                             nsamples=10000)\n",
    "print(examples_inner.shape[0], examples_outer.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора $\\mathcal{F}(\\mathbf{\\cdot})$\n",
    "\n",
    "Итак, к этому моменту у вас должно быть все готово для обучения нейросети $\\mathcal{F}(\\mathbf{x})$, которая будет разделять \"обычные\" и \"аномальные\" примеры. Более конкретно, у вас должны быть готовы:\n",
    "- обученный генератор - нейросетевая модель, преобразующая векторы $z\\in\\mathbb{Z}$ в примеры $x$ в пространстве признаков $\\mathbb{X}$:\n",
    "$$\n",
    "\\mathcal{G}(\\cdot): \\mathbb{Z}\\to\\mathbb{X}\n",
    "$$\n",
    "- механизм равномерного порождения \"обычных\" и \"аномальных\" векторов $z\\in\\mathbb{Z}$. Для этих векторов заранее известны метки, являются ли они обычными ($y=0$) или аномальными ($y=1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРИМЕЧАНИЕ**\n",
    "Генератор на этом этапе обучать не нужно! Не забудьте переключить его в режим исполнения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При необходимости можно загрузить нужное состояние генератора\n",
    "gen = Generator(n_inputs=latent_dim)\n",
    "gen.load_state_dict(torch.load('./path/to/model/checkpoint/gen.pt'))\n",
    "gen = gen.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нужно описать классификатор. Это нейросеть, выполняющая задачу бинарной классификации. Скорее всего, вам захочется сделать ее свёрточной.\n",
    "\n",
    "ПРИМЕЧАНИЕ: не забудьте, что здесь уже будет использоваться постановка задачи бинарной классификации. Подумайте, какими в этом случае должны быть:\n",
    "- размерность выходного слоя классификатора;\n",
    "- функция активации выходного слоя;\n",
    "- функция потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ################################\n",
    "        ###    YOUR CODE HERE        ###\n",
    "        ################################\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "clf = clf.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model_gen: torch.nn.Module, \n",
    "                     model_clf: torch.nn.Module,\n",
    "                     batch_size = 64,\n",
    "                     batches_per_epoch = 128,\n",
    "                     max_epochs = 512):\n",
    "    \n",
    "    '''\n",
    "    В этой функции следует описать цикл оптимизации нейросети-классификатора.\n",
    "    Не забудьте, что примеры для этой нейросети вы порождаете генератором, обученным выше.\n",
    "    При этом шумовые векторы z для генератора вы порождаете, используя функции сбалансированного сэмплирования,\n",
    "        описанные выше.\n",
    "        \n",
    "    Не забывайте и здесь применять маску к данным, порождаемым генератором!\n",
    "    '''\n",
    "    \n",
    "    ################################\n",
    "    ###    YOUR CODE HERE        ###\n",
    "    ################################\n",
    "    \n",
    "    val_loss_history = []\n",
    "    model_gen.eval()\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print(f'Starting epoch {epoch+1} of {max_epochs}')\n",
    "        \n",
    "        model_clf.train()\n",
    "        \n",
    "        ####################################\n",
    "        ###    YOUR CODE HERE            ###\n",
    "        ### classifier optimization loop ###\n",
    "        ####################################\n",
    "                \n",
    "        \n",
    "        model_clf.eval()\n",
    "        val_loss_epoch = 0.0\n",
    "        \n",
    "        ####################################\n",
    "        ###    YOUR CODE HERE            ###\n",
    "        ###  classifier evaluation loop  ###\n",
    "        ####################################\n",
    "            \n",
    "        val_loss_history.append(val_loss_epoch)\n",
    "        print('Eval loss on epoch %d: %f' % (epoch+1, loss_epoch))\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "    return val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_history = train_classifier(model_gen=gen,\n",
    "                                    model_clf=clf,\n",
    "                                    batch_size = 128,\n",
    "                                    batches_per_epoch = 128,\n",
    "                                    max_epochs = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение классификатора $\\mathcal{F}(\\mathbf{\\cdot})$\n",
    "\n",
    "Вы проделали большую работу! Теперь можно применить обученный классификатор для идентификации аномалий в данных.\n",
    "\n",
    "Для этого нужно применить ее ко всем данным выборки.\n",
    "\n",
    "- создайте новый экземпляр класса `DS`;\n",
    "- создайте `dataloader` на основе этих данных. При этом не перемешивайте его: сейчас важен порядок обработки и ответов классификатора;\n",
    "- в цикле примените классификатор $\\mathcal{F}(\\mathbf{\\cdot})$ ко всем данным; сохраните ответы классификатора в массив;\n",
    "- запишите индексы элементов выборки, которые классифицированы как аномальные, в массив `idx_anomalies`;\n",
    "- воспользуйтесь заготовкой кода ниже для отображения объектов, которые классифицированы как аномальные и обычные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = DS('/path/to/pv_data_projected_all.normed01.npy',\n",
    "             '/path/to/gh_data_projected_all.normed01.npy',\n",
    "             '/path/to/mask_256.npy',\n",
    "             train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(ds_test, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "clf.load_state_dict(torch.load('/path/to/classifier/checkpoint/file.pt'))\n",
    "clf = clf.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ результатов.\n",
    "\n",
    "Примените обученный классификатор ко всем данным изначальной выборки.\n",
    "\n",
    "Проанализируйте результаты:\n",
    "- каково распределение вероятностей примеров быть аномальными, оцениваемое этим классификатором. Отобразите в виде гистограммы.\n",
    "- Выберите пороговое значение для этих оценок вероятностей. Если применить разделение по этому пороговому значению, - каково количество примеров, отнесенных к обычным и к аномальным?\n",
    "- Отобразите несколько состояний стратосферы, отнесенных к обычным, и несколько состояний, отнесенных к аномальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
